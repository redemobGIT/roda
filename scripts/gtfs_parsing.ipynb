{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "28be5451-9423-4fb5-8447-1810b93db708",
      "metadata": {
        "id": "28be5451-9423-4fb5-8447-1810b93db708"
      },
      "source": [
        "# Introdução"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2cc00e-8700-4eec-b105-4d096113f348",
      "metadata": {
        "id": "6a2cc00e-8700-4eec-b105-4d096113f348"
      },
      "source": [
        "Este script segue o procedimento apresentado na Cartilha GTFS do MOB 4.0 para consolidar dados de transporte público em uma estrutura consistente com a Especiicação Geral de Feeds de Transporte Público, [conforme utilizada pelo Google](https://developers.google.com/transit/gtfs?hl=pt-br). A cartilha contém instruções a respeito de como deve ser a estrutura dos dados de entrada, estrutura essa que é essencial para que o código que aqui consta se comporte como esperado.\n",
        "\n",
        "Ao longo deste script, pontualmente, são feitas considerações gerais a respeito do funcionamento das linhas de código, mas não se entende que seja necessário conhecimento prévio de linguagem de programação. O código foi pensado de maneira que ele apenas necessita, logo no início, dos inputs do usuário. Feito isso, após processamento, o scritp irá retornar um arquivo ZIP o qual contém os arquivos GTFS básicos. Não obstante, como o código foi completamente disponibilizado, de forma transparente, sugestões de melhora e aperfeiçoamento são bem vindas e podem ser incorporadas para versões futuras.\n",
        "\n",
        "Atualmente o código apenas suporta a construção de redes de ônnibus regulares, sobretudo porque este é o caso mais comum presente nas cidades brasileiras. No entanto, versões futuras irão incorporar outros modos.\n",
        "\n",
        "Este código é a primeira versão publicada pelo MOB 4.0 e antecipam-se novas edições com funcionamento aprimorado, seja por nossa própria iniciativa, seja após sugestão de eventuais usuários."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6f230ab-9e36-4975-ba0a-e11a4734286c",
      "metadata": {
        "id": "c6f230ab-9e36-4975-ba0a-e11a4734286c"
      },
      "source": [
        "# Instruções"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f91e00c4-df04-4fdf-bd3d-47e1b50b6e7a",
      "metadata": {
        "id": "f91e00c4-df04-4fdf-bd3d-47e1b50b6e7a"
      },
      "source": [
        "**Agora, a ideia é que o usuário forneça os arquivos necessários para o bom funcionamento do script. Feito isso, basta processar o script e ao final ele produzirá os arquivos GTFS para o sistema de transporte público em questão.** Esta primeira versão consegue lidar com sistemas de uma única cidade. Caso haja linhas intermunicipais que sejam indispensáveis para o sistema, deve ser considerado apenas a parte do trajeto que se localiza no interior do município. Posto isso, às instruções:\n",
        "\n",
        "- Fornecer código do IBGE para o município, conforme lista hospedada [aqui](https://www.ibge.gov.br/explica/codigos-dos-municipios.php);\n",
        "- Fornecer caminho no computador para a planilha operacional que compõe a cartilha;\n",
        "- Fornecer caminho no computador para o arquivo geográfico com os pontos de parada;\n",
        "    - Em não havendo disponibilidade dos pontos de ônibus, o script irá assumir que há pontos de ônibus a cada 350 metros, ao longo do itinerário, por padrão. Caso se queira fornecer uma outra distância, preencher a variável espacamento com uma distância que se ache mais apropriada.\n",
        "- Fornecer caminho no computador para o arquivo geográfico com os itinerários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cce1e21-f15c-4fc0-95f3-16972d37e43a",
      "metadata": {
        "id": "8cce1e21-f15c-4fc0-95f3-16972d37e43a"
      },
      "outputs": [],
      "source": [
        "# Substitituir None com o código do IBGE para o município\n",
        "ibge_id = 3143302\n",
        "\n",
        "# Substitituir None com o caminho para a planilha excel\n",
        "planilha_operacional = '/content/planilha_gtfs.xlsx'\n",
        "\n",
        "# Substituir None com o caminho para o arquivo geográfico\n",
        "# com pontos de parada, se houver\n",
        "pontos_de_parada = None#'/content/pontos_bus.kml'\n",
        "\n",
        "# Substituir None com o caminho para o arquivo geográfico com itinerarios\n",
        "itinerarios = '/content/linhas_mc.kml'\n",
        "\n",
        "# Escolher distância em metros entre pontos de parada.\n",
        "# Apenas se os pontos de parada não forem fornecidos e caso\n",
        "# não se deseje utilizar o valor padrão de 350 m\n",
        "espacamento = 350"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e6eece0-349d-4790-8d8a-2ad0c89fe06b",
      "metadata": {
        "id": "3e6eece0-349d-4790-8d8a-2ad0c89fe06b"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d353a65f-06db-4723-b6e6-1afb647449db",
      "metadata": {
        "id": "d353a65f-06db-4723-b6e6-1afb647449db"
      },
      "source": [
        "Aqui é feita a instalação e a importação das bibliotecas necessárias, assim como também são feitos alguns ajustes iniciais gerais."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install osmnx\n",
        "!pip install h3\n",
        "!pip install tobler\n",
        "!pip install --no-deps geobr\n",
        "!pip install git+https://github.com/remix/partridge.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qJcy0QxF13v4",
        "outputId": "5e1474be-c2f1-4f47-e49c-6ca78526cc85"
      },
      "id": "qJcy0QxF13v4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: osmnx in /usr/local/lib/python3.10/dist-packages (1.9.4)\n",
            "Requirement already satisfied: geopandas<0.15,>=0.12 in /usr/local/lib/python3.10/dist-packages (from osmnx) (0.14.4)\n",
            "Requirement already satisfied: networkx<3.4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from osmnx) (3.3)\n",
            "Requirement already satisfied: numpy<1.27,>=1.20 in /usr/local/lib/python3.10/dist-packages (from osmnx) (1.26.4)\n",
            "Requirement already satisfied: pandas<2.3,>=1.1 in /usr/local/lib/python3.10/dist-packages (from osmnx) (2.2.2)\n",
            "Requirement already satisfied: requests<2.33,>=2.27 in /usr/local/lib/python3.10/dist-packages (from osmnx) (2.32.3)\n",
            "Requirement already satisfied: shapely<2.1,>=2.0 in /usr/local/lib/python3.10/dist-packages (from osmnx) (2.0.6)\n",
            "Requirement already satisfied: fiona>=1.8.21 in /usr/local/lib/python3.10/dist-packages (from geopandas<0.15,>=0.12->osmnx) (1.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas<0.15,>=0.12->osmnx) (24.1)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas<0.15,>=0.12->osmnx) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=1.1->osmnx) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=1.1->osmnx) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=1.1->osmnx) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<2.33,>=2.27->osmnx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<2.33,>=2.27->osmnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<2.33,>=2.27->osmnx) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<2.33,>=2.27->osmnx) (2024.8.30)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas<0.15,>=0.12->osmnx) (24.2.0)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas<0.15,>=0.12->osmnx) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas<0.15,>=0.12->osmnx) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas<0.15,>=0.12->osmnx) (0.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=1.1->osmnx) (1.16.0)\n",
            "Requirement already satisfied: h3 in /usr/local/lib/python3.10/dist-packages (3.7.7)\n",
            "Requirement already satisfied: tobler in /usr/local/lib/python3.10/dist-packages (0.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tobler) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tobler) (2.2.2)\n",
            "Requirement already satisfied: geopandas>=0.13 in /usr/local/lib/python3.10/dist-packages (from tobler) (0.14.4)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (from tobler) (1.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tobler) (1.13.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from tobler) (0.14.4)\n",
            "Requirement already satisfied: rasterstats in /usr/local/lib/python3.10/dist-packages (from tobler) (0.20.0)\n",
            "Requirement already satisfied: libpysal in /usr/local/lib/python3.10/dist-packages (from tobler) (4.12.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tobler) (4.66.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from tobler) (1.4.2)\n",
            "Requirement already satisfied: fiona>=1.8.21 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.13->tobler) (1.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.13->tobler) (24.1)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.13->tobler) (3.7.0)\n",
            "Requirement already satisfied: shapely>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.13->tobler) (2.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tobler) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tobler) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->tobler) (2024.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.10 in /usr/local/lib/python3.10/dist-packages (from libpysal->tobler) (4.12.3)\n",
            "Requirement already satisfied: platformdirs>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from libpysal->tobler) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.10/dist-packages (from libpysal->tobler) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.10/dist-packages (from libpysal->tobler) (1.5.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio->tobler) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio->tobler) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio->tobler) (2024.8.30)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio->tobler) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio->tobler) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio->tobler) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio->tobler) (3.1.4)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from rasterstats->tobler) (3.19.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->tobler) (0.5.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.10->libpysal->tobler) (2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->tobler) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->libpysal->tobler) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->libpysal->tobler) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->libpysal->tobler) (2.2.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->libpysal->tobler) (3.5.0)\n",
            "Requirement already satisfied: geobr in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Collecting git+https://github.com/remix/partridge.git\n",
            "  Cloning https://github.com/remix/partridge.git to /tmp/pip-req-build-43vrq9q3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/remix/partridge.git /tmp/pip-req-build-43vrq9q3\n",
            "  Resolved https://github.com/remix/partridge.git to commit 7b3d2c70281ef4f5437c3e48d786569c1702ebd8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset_normalizer in /usr/local/lib/python3.10/dist-packages (from partridge==1.1.2) (3.3.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from partridge==1.1.2) (3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from partridge==1.1.2) (2.2.2)\n",
            "Requirement already satisfied: isoweek in /usr/local/lib/python3.10/dist-packages (from partridge==1.1.2) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->partridge==1.1.2) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->partridge==1.1.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->partridge==1.1.2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->partridge==1.1.2) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->partridge==1.1.2) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "824c97a2-13d8-4832-a8ad-8240f77836d3",
      "metadata": {
        "id": "824c97a2-13d8-4832-a8ad-8240f77836d3"
      },
      "outputs": [],
      "source": [
        "import calendar\n",
        "import re\n",
        "import datetime as dt\n",
        "import requests\n",
        "import urllib.request\n",
        "from uuid import uuid4\n",
        "\n",
        "import fiona\n",
        "import geobr\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import osmnx as ox\n",
        "import pandas as pd\n",
        "import partridge as ptg\n",
        "from shapely.geometry import Point, LineString\n",
        "from shapely.ops import linemerge\n",
        "from tobler.util import h3fy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47e35777-280e-4d41-9047-ef06656363cc",
      "metadata": {
        "id": "47e35777-280e-4d41-9047-ef06656363cc"
      },
      "outputs": [],
      "source": [
        "# enable KML support which is disabled by default\n",
        "fiona.drvsupport.supported_drivers['KML'] = 'rw'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e442c38d-b2d2-4289-b0c4-df8d2ff659a6",
      "metadata": {
        "id": "e442c38d-b2d2-4289-b0c4-df8d2ff659a6"
      },
      "outputs": [],
      "source": [
        "path_operations = planilha_operacional\n",
        "path_stops = pontos_de_parada\n",
        "spacing = espacamento\n",
        "path_routes = itinerarios"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01080fb4-7c89-4b7a-af02-8c1c69ae9351",
      "metadata": {
        "id": "01080fb4-7c89-4b7a-af02-8c1c69ae9351"
      },
      "source": [
        "# Variáveis de Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e405526-c59a-4d3e-a197-26baeb7cbb81",
      "metadata": {
        "id": "1e405526-c59a-4d3e-a197-26baeb7cbb81"
      },
      "outputs": [],
      "source": [
        "borders = geobr.read_municipality(ibge_id)\n",
        "\n",
        "EPSG = borders.estimate_utm_crs('SIRGAS 2000').to_epsg()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8ef60bd-9e10-4899-81fd-4bd2b73a3d92",
      "metadata": {
        "id": "b8ef60bd-9e10-4899-81fd-4bd2b73a3d92"
      },
      "outputs": [],
      "source": [
        "road_graph = ox.graph_from_polygon(\n",
        "    borders.to_crs(4326).geometry.squeeze(),\n",
        "    network_type='drive',\n",
        "    )\n",
        "\n",
        "road_graph = ox.project_graph(\n",
        "    road_graph,\n",
        "    to_crs=EPSG,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bef1e151-b354-4ac8-a12a-88e224d31973",
      "metadata": {
        "id": "bef1e151-b354-4ac8-a12a-88e224d31973"
      },
      "source": [
        "# A Classe Feed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f514c1ed-38ee-41a3-9e8c-71126ecf4c18",
      "metadata": {
        "id": "f514c1ed-38ee-41a3-9e8c-71126ecf4c18"
      },
      "source": [
        "Este código usa as funcionalidades da biblioteca [Partridge](https://github.com/remix/partridge), pensada para rápida leitura e manipulação de arquivos GTFS. Nesse sentido, primeiro é gerado um objeto para armazenar os arquivos GTFS conforme eles são gerados. Aqui, optamos pela forma mais simples e funcional e rápida de implementação, mas essa primeira parte passará por refinamentos na próxima edição do Script."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "url = 'https://s3.amazonaws.com/mobilibus-uploads/gtfs/GTFSBHTRANSCON.zip'\n",
        "filename = 'base_feed.zip'\n",
        "\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "id": "OiSznqV-1kXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab137a94-2740-4ed1-afcf-e1c2ce32f74b"
      },
      "id": "OiSznqV-1kXa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('base_feed.zip', <http.client.HTTPMessage at 0x7de4d7d5fbb0>)"
            ]
          },
          "metadata": {},
          "execution_count": 541
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "462835dd-c742-4fcc-b3bd-f7f04ffa3e9d",
      "metadata": {
        "id": "462835dd-c742-4fcc-b3bd-f7f04ffa3e9d"
      },
      "outputs": [],
      "source": [
        "feed = ptg.load_feed(\n",
        "    'base_feed.zip',\n",
        "    )\n",
        "\n",
        "filenames = [\n",
        "    p\n",
        "    for p\n",
        "    in dir(feed)\n",
        "    if isinstance(getattr(feed, p), pd.DataFrame)\n",
        "    ]\n",
        "\n",
        "for file in filenames:\n",
        "    feed.set(\n",
        "        f\"{file}.txt\",\n",
        "        ptg.utilities.empty_df(),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15d45a54-6c5d-4b63-aa7f-f60b0486e8d6",
      "metadata": {
        "id": "15d45a54-6c5d-4b63-aa7f-f60b0486e8d6"
      },
      "source": [
        "# Leitura dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e95b216-0f5c-443c-a5fa-701b66cdbf53",
      "metadata": {
        "id": "2e95b216-0f5c-443c-a5fa-701b66cdbf53"
      },
      "outputs": [],
      "source": [
        "def _assign_ids(df):\n",
        "    number_of_ids = len(df)\n",
        "    return [\n",
        "        str(uuid4()).split('-')[0]\n",
        "        for i\n",
        "        in range(number_of_ids)\n",
        "        ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c192252e-181f-415e-bf35-2ab835422f71",
      "metadata": {
        "id": "c192252e-181f-415e-bf35-2ab835422f71"
      },
      "outputs": [],
      "source": [
        "def _load_operations(inpath):\n",
        "    return pd.read_excel(\n",
        "        'planilha_gtfs.xlsx',\n",
        "        sheet_name=None,\n",
        "        dtype=str\n",
        "        )\n",
        "\n",
        "\n",
        "def read_stops(path_stops, proj_crs):\n",
        "    return (\n",
        "        gpd\n",
        "        .read_file(path_stops)\n",
        "        .rename(columns=lambda c: c.casefold())\n",
        "        .rename(\n",
        "            columns={\n",
        "                'name': 'stop_name',\n",
        "                'description':'stop_desc'\n",
        "                },\n",
        "            errors='ignore',\n",
        "            )\n",
        "        .reindex(\n",
        "            columns=[\n",
        "                'stop_name',\n",
        "                'stop_desc',\n",
        "                'geometry',\n",
        "                ]\n",
        "            )\n",
        "        .to_crs(proj_crs)\n",
        "        .assign(stop_id=_assign_ids)\n",
        "        )\n",
        "\n",
        "\n",
        "def _read_routes(path, proj_crs):\n",
        "    df = gpd.GeoDataFrame()\n",
        "\n",
        "    for layer in fiona.listlayers(path):\n",
        "        s = gpd.read_file(path, driver='KML', layer=layer)\n",
        "        df = pd.concat([df, s], ignore_index=True)\n",
        "\n",
        "    return (\n",
        "        df\n",
        "        .to_crs(proj_crs)\n",
        "        .rename(columns=lambda c: c.casefold())\n",
        "        .assign(\n",
        "            description=lambda x: x.description.str.casefold()\n",
        "            )\n",
        "        .assign(\n",
        "            description=lambda x: np.where(\n",
        "                x.description == 'volta',\n",
        "                '1',\n",
        "                '0',\n",
        "                ),\n",
        "            shape_id=lambda x: x.name.astype(str) + '-' + x.description\n",
        "            )\n",
        "            .reindex(\n",
        "                columns=[\n",
        "                    'shape_id',\n",
        "                    'geometry',\n",
        "                    ]\n",
        "                )\n",
        "        )\n",
        "\n",
        "\n",
        "def load_feed(\n",
        "    path_operations=None,\n",
        "    path_stops=None,\n",
        "    path_routes=None,\n",
        "    proj_crs=EPSG,\n",
        "    ):\n",
        "    ops = _load_operations(path_operations)\n",
        "\n",
        "    stops = None\n",
        "    if path_stops is not None:\n",
        "        stops = read_stops(path_stops, proj_crs)\n",
        "\n",
        "    routes = None\n",
        "    if path_routes is not None:\n",
        "        routes = _read_routes(path_routes, proj_crs)\n",
        "\n",
        "    return ops, stops, routes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae7cb4f9-ab08-46c2-8a09-b70143ca043b",
      "metadata": {
        "id": "ae7cb4f9-ab08-46c2-8a09-b70143ca043b"
      },
      "outputs": [],
      "source": [
        "ops, stops, routes = load_feed(\n",
        "    path_operations=path_operations,\n",
        "    path_routes=path_routes,\n",
        "    path_stops=path_stops,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a10294bd-d89b-4280-a28e-66396a91ea37",
      "metadata": {
        "id": "a10294bd-d89b-4280-a28e-66396a91ea37"
      },
      "source": [
        "# GTFS Feed: Dados Não Espaciais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa936c5-10da-4a49-b51e-c105c593d9a2",
      "metadata": {
        "id": "eaa936c5-10da-4a49-b51e-c105c593d9a2"
      },
      "outputs": [],
      "source": [
        "def _rename_operations_columns(ops):\n",
        "    d = {\n",
        "        'id_agencia': 'agency_id',\n",
        "        'linha': 'route_id',\n",
        "        'nome_line': 'route_long_name',\n",
        "        'sentido': 'direction_id',\n",
        "        'hora_inicio': 'start_time',\n",
        "        'hora_fim': 'end_time',\n",
        "        'data_inicio': 'start_date',\n",
        "        'data_fim': 'end_date',\n",
        "        'intervalo_minutos': 'headway_secs',\n",
        "        'ciclo_viagem_medio': 'travel_time',\n",
        "        }\n",
        "\n",
        "    d = d | {dia: day.casefold() for dia, day in zip(ops.iloc[:, -7:], calendar.day_name)}\n",
        "\n",
        "    return ops.rename(columns=d)\n",
        "\n",
        "\n",
        "def _build_agency(data):\n",
        "    return data.rename(\n",
        "        columns={\n",
        "            'id_agencia': 'agency_id',\n",
        "            'nome_agencia': 'agency_name',\n",
        "            'fuso_horario': 'agency_timezone',\n",
        "            'site_agencia': 'agency_url',\n",
        "            'linguagem_agencia': 'agency_lang'\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "def _get_service_ids(df):\n",
        "    u = df.monday.replace({'1': 'U', '0': '_'})\n",
        "    s = df.saturday.replace({'1': 'S', '0': '_'})\n",
        "    d = df.sunday.replace({'1': 'D', '0': '_'})\n",
        "\n",
        "    return df.assign(\n",
        "        service_id=u + s + d\n",
        "    )\n",
        "\n",
        "\n",
        "def _get_trip_ids(df):\n",
        "    trip_counts = (\n",
        "        df\n",
        "        .groupby([\n",
        "            'route_id',\n",
        "            'direction_id',\n",
        "            'service_id',\n",
        "        ])\n",
        "        .cumcount()\n",
        "        .add(1)\n",
        "        .astype('str')\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        df\n",
        "        .assign(\n",
        "            direction_id=lambda x: x.direction_id.str.casefold()\n",
        "            )\n",
        "        .assign(\n",
        "            direction_id=lambda x: np.where(x.direction_id == 'volta', '1', '0')\n",
        "            )\n",
        "        .assign(\n",
        "            trip_id=lambda x: (\n",
        "                x.route_id\n",
        "                + '-'\n",
        "                + x.service_id.str.replace('_', '')\n",
        "                + '-'\n",
        "                + x.direction_id.replace({'0': 'IDA', '1': 'VOLTA'})\n",
        "                + '-'\n",
        "                + trip_counts\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "def _add_ids(operations):\n",
        "    return (\n",
        "        operations\n",
        "        .pipe(_get_service_ids)\n",
        "        .pipe(_get_trip_ids)\n",
        "        )\n",
        "\n",
        "\n",
        "def _parse_frequencies(ops, feed):\n",
        "    mask = ops.headway_secs.notnull() # TODO think on more sophisticated mask\n",
        "    frequencies = ops.loc[mask]\n",
        "    if frequencies.empty:\n",
        "        feed.set(\n",
        "            f\"frequencies.txt\",\n",
        "            ptg.utilities.empty_df()\n",
        "            )\n",
        "        return feed\n",
        "\n",
        "    freqs = (\n",
        "        frequencies\n",
        "        .reindex(\n",
        "            columns=[\n",
        "                'trip_id',\n",
        "                'start_time',\n",
        "                'end_time',\n",
        "                'headway_secs',\n",
        "                ]\n",
        "            )\n",
        "        .assign(\n",
        "            exact_times=0,\n",
        "            # original data was in minutes\n",
        "            headway_secs=lambda x: x.headway_secs.astype(int) * 60\n",
        "            )\n",
        "        )\n",
        "\n",
        "    feed.set(\n",
        "        'frequencies.txt',\n",
        "        freqs,\n",
        "        )\n",
        "\n",
        "    return feed\n",
        "\n",
        "\n",
        "def _parse_routes(ops, feed):\n",
        "    cols = [\n",
        "        'route_id',\n",
        "        'agency_id',\n",
        "        'route_short_name',\n",
        "        'route_type',\n",
        "        ]\n",
        "    routes = (\n",
        "        ops\n",
        "        .assign(\n",
        "            #TODO: allow multiple agencies\n",
        "            agency_id=lambda x: x.agency_id,\n",
        "            route_short_name=lambda x: x.route_id,\n",
        "            route_type=3,\n",
        "            )\n",
        "        .reindex(\n",
        "            columns=cols,\n",
        "            )\n",
        "        .drop_duplicates(cols)\n",
        "        )\n",
        "\n",
        "    feed.set('routes.txt', routes)\n",
        "\n",
        "    return feed\n",
        "\n",
        "\n",
        "def _parse_trips(ops, feed):\n",
        "    cols = [\n",
        "        'route_id',\n",
        "        'service_id',\n",
        "        'trip_id',\n",
        "        'direction_id',\n",
        "        'shape_id',\n",
        "        ]\n",
        "\n",
        "    schedule = (\n",
        "        ops\n",
        "        .assign(\n",
        "            shape_id=lambda x: (\n",
        "                x.route_id\n",
        "                + '-'\n",
        "                + x.direction_id\n",
        "                )\n",
        "            )\n",
        "        .drop_duplicates(cols)\n",
        "        )\n",
        "\n",
        "    feed.set(\n",
        "        'trips.txt',\n",
        "        schedule.reindex(columns=cols),\n",
        "        )\n",
        "\n",
        "    return feed, schedule\n",
        "\n",
        "\n",
        "def _parse_calendar(ops, feed):\n",
        "    days = map(lambda s: s.casefold(), calendar.day_name)\n",
        "    cols = ['service_id'] + list(days) + ['start_date', 'end_date']\n",
        "    feed_calendar = (\n",
        "        ops\n",
        "        .drop_duplicates(cols)\n",
        "        .reindex(columns=cols)\n",
        "        .astype(int, errors='ignore')\n",
        "        )\n",
        "\n",
        "    feed.set('calendar.txt', feed_calendar)\n",
        "\n",
        "    return feed\n",
        "\n",
        "\n",
        "def _parse_operations(\n",
        "    ops,\n",
        "    feed,\n",
        "    ):\n",
        "    feed = _parse_frequencies(ops, feed)\n",
        "    feed = _parse_routes(ops, feed)\n",
        "    feed, schedule = _parse_trips(ops, feed)\n",
        "    feed = _parse_calendar(ops, feed)\n",
        "\n",
        "    return feed, schedule\n",
        "\n",
        "\n",
        "def build_nonspatial_files(ops, feed):\n",
        "    agency, operations = ops.values()\n",
        "\n",
        "    feed.set(\n",
        "        f\"agency.txt\",\n",
        "        _build_agency(agency)\n",
        "        )\n",
        "\n",
        "    feed, schedule = (\n",
        "        operations\n",
        "        .pipe(_rename_operations_columns)\n",
        "        .pipe(_add_ids)\n",
        "        .pipe(_parse_operations, feed)\n",
        "        )\n",
        "\n",
        "    return feed, schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f0fb42-103f-4bab-97b5-e8346fe69ee4",
      "metadata": {
        "id": "c2f0fb42-103f-4bab-97b5-e8346fe69ee4"
      },
      "outputs": [],
      "source": [
        "feed, schedule = build_nonspatial_files(ops, feed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41571179-52b2-4dda-b600-7fbad982ad23",
      "metadata": {
        "id": "41571179-52b2-4dda-b600-7fbad982ad23"
      },
      "source": [
        "# GTFS Feed: Arquivos Espaciais"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4f453d1-38d5-4fe2-9ef1-0f8e506bf201",
      "metadata": {
        "id": "b4f453d1-38d5-4fe2-9ef1-0f8e506bf201"
      },
      "source": [
        "## Pontos de parada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbeba69f-b15c-4f83-b53e-8365d24dde9b",
      "metadata": {
        "id": "cbeba69f-b15c-4f83-b53e-8365d24dde9b"
      },
      "outputs": [],
      "source": [
        "def _name_stops(df):\n",
        "    rng = np.random.default_rng(42)\n",
        "    word_site = \"https://www.mit.edu/~ecprice/wordlist.10000\"\n",
        "    response = requests.get(word_site)\n",
        "    WORDS = response.content.splitlines()\n",
        "\n",
        "    chosen_words = rng.choice(\n",
        "        WORDS,\n",
        "        size=len(df),\n",
        "        replace=False,\n",
        "        )\n",
        "    return [str(w, 'utf-8').upper() for w in chosen_words]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a481de18-16a0-4401-bee2-141709429dd0",
      "metadata": {
        "id": "a481de18-16a0-4401-bee2-141709429dd0"
      },
      "outputs": [],
      "source": [
        "def _add_spacings(df, spacing, stops_by_route):\n",
        "    # TODO: exception handling and all\n",
        "    if spacing:\n",
        "        # TODO: different spacings per route\n",
        "        return df.assign(spacing=spacing)\n",
        "\n",
        "    if stops_by_route:\n",
        "        # TO DO: make it accept scalar: same value for all\n",
        "        return (\n",
        "            df\n",
        "            .merge(\n",
        "                stops_by_route.rename('number_stops'),\n",
        "                left_on='route_id',\n",
        "                right_index=True,\n",
        "                )\n",
        "            .pipe(_interstop_distance)\n",
        "            .drop(columns='number_stops')\n",
        "        )\n",
        "\n",
        "\n",
        "def _break_route(row):\n",
        "    route_geometry = row.geometry\n",
        "    spacings = np.arange(0, route_geometry.length, row.spacing)\n",
        "    route_stops = [route_geometry.interpolate(s) for s in spacings]\n",
        "\n",
        "    if route_geometry.length - spacings[-1] > row.spacing / 2 :\n",
        "        return route_stops + [Point(route_geometry.coords[-1])]\n",
        "\n",
        "    return route_stops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77f36fc2-fbee-4030-8039-cc4b1e53fcf0",
      "metadata": {
        "id": "77f36fc2-fbee-4030-8039-cc4b1e53fcf0"
      },
      "outputs": [],
      "source": [
        "def _get_grid(road_graph, proj_crs):\n",
        "    _, e = ox.graph_to_gdfs(road_graph)\n",
        "    city_bounds = gpd.GeoSeries(\n",
        "        data=e.unary_union.envelope,\n",
        "        crs=proj_crs,\n",
        "        )\n",
        "    return h3fy(city_bounds, resolution=9)\n",
        "\n",
        "\n",
        "def _select_stop_at_random(gdf):\n",
        "    \"\"\"\n",
        "    Given a grid with a cluster of stops within each cell,\n",
        "    randomly selects one of them as the representative: using\n",
        "    centroids may lead them to locate in weird places, depending\n",
        "    on street network topology.\n",
        "    \"\"\"\n",
        "    #TODO: when selecting points randomly, assign\n",
        "    # higher probabilities to the ones closer\n",
        "    # to the centroid of the set of points\n",
        "    rng = np.random.default_rng(42)\n",
        "    return (\n",
        "        gdf\n",
        "        .geometry\n",
        "        .map(\n",
        "            lambda g: (\n",
        "                g\n",
        "                if g.geom_type == 'Point'\n",
        "                else rng.choice(list(g.geoms), 1)[0]\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "def _groupby_grid_cell(stops_by_hex):\n",
        "    return (\n",
        "        stops_by_hex\n",
        "        .dissolve('hex_id')\n",
        "        .reset_index()\n",
        "        .assign(\n",
        "            geometry=_select_stop_at_random\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "def _cluster_stops(stops, road_graph, proj_crs):\n",
        "    grid = _get_grid(road_graph, proj_crs)\n",
        "    return (\n",
        "        stops\n",
        "        .sjoin(grid)\n",
        "        .reindex(columns=['hex_id', 'geometry'])\n",
        "        .pipe(_groupby_grid_cell)\n",
        "        )\n",
        "\n",
        "\n",
        "def _stops_by_route(df, proj_crs):\n",
        "    return (\n",
        "        df\n",
        "        .assign(\n",
        "            stops=lambda x: x.apply(\n",
        "                _break_route,\n",
        "                axis='columns'\n",
        "                )\n",
        "            )\n",
        "        .explode('stops', ignore_index=True)\n",
        "        .set_geometry('stops')\n",
        "        .drop(columns='geometry')\n",
        "        .rename_geometry('geometry')\n",
        "        .set_crs(proj_crs)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb72b4e7-4cc2-46f6-a517-4eb85b1c0966",
      "metadata": {
        "id": "fb72b4e7-4cc2-46f6-a517-4eb85b1c0966"
      },
      "outputs": [],
      "source": [
        "def parse_stops(stops, proj_crs):\n",
        "    return (\n",
        "        stops\n",
        "        .reindex(\n",
        "            columns=[\n",
        "                'stop_id',\n",
        "                'stop_name',\n",
        "                'stop_desc',\n",
        "                'geometry'\n",
        "                ]\n",
        "            )\n",
        "        .to_crs(4326)\n",
        "        .assign(\n",
        "            stop_name=_name_stops,\n",
        "            stop_lat=lambda x: x.geometry.y,\n",
        "            stop_lon=lambda x: x.geometry.x,\n",
        "            )\n",
        "        .to_crs(proj_crs)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d1deec0-09ce-4a4d-ba8f-514aa14a91f9",
      "metadata": {
        "id": "0d1deec0-09ce-4a4d-ba8f-514aa14a91f9"
      },
      "outputs": [],
      "source": [
        "def stops_from_route(\n",
        "    routes,\n",
        "    road_graph,\n",
        "    spacing,\n",
        "    stops_by_route,\n",
        "    proj_crs,\n",
        "    ):\n",
        "    return (\n",
        "        routes\n",
        "        .pipe(_add_spacings, spacing, stops_by_route)\n",
        "        .pipe(_stops_by_route, proj_crs)\n",
        "        .pipe(_cluster_stops, road_graph, proj_crs)\n",
        "        .rename(columns={'hex_id': 'stop_id'})\n",
        "        .pipe(parse_stops, proj_crs)\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c6df5a7-7ceb-4dc7-a70c-b8c5364189a3",
      "metadata": {
        "id": "8c6df5a7-7ceb-4dc7-a70c-b8c5364189a3"
      },
      "outputs": [],
      "source": [
        "def build_stops(\n",
        "    feed,\n",
        "    routes,\n",
        "    stops=None,\n",
        "    road_graph=road_graph,\n",
        "    spacing=350,\n",
        "    stops_by_route=None,\n",
        "    proj_crs=EPSG,\n",
        "    ):\n",
        "    if stops is not None:\n",
        "        feed.set(\n",
        "            'stops.txt',\n",
        "            parse_stops(stops, proj_crs).drop(columns='geometry')\n",
        "            )\n",
        "        return feed\n",
        "\n",
        "    stops = stops_from_route(\n",
        "        routes,\n",
        "        road_graph,\n",
        "        spacing,\n",
        "        stops_by_route,\n",
        "        proj_crs,\n",
        "        )\n",
        "    feed.set(\n",
        "        'stops.txt',\n",
        "        stops.drop(columns='geometry')\n",
        "        )\n",
        "    return feed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3faca39a-b8ba-4f4d-8c47-fd3bc4335781",
      "metadata": {
        "id": "3faca39a-b8ba-4f4d-8c47-fd3bc4335781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b08e609a-22eb-4726-e394-622a5a3ad648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyproj/crs/crs.py:1295: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n",
            "  proj = self._crs.to_proj4(version=version)\n"
          ]
        }
      ],
      "source": [
        "feed = build_stops(\n",
        "    feed,\n",
        "    routes,\n",
        "    stops,\n",
        "    spacing=spacing,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da529f11-6a61-4c59-ac3d-e99bbc0ae1d5",
      "metadata": {
        "id": "da529f11-6a61-4c59-ac3d-e99bbc0ae1d5"
      },
      "source": [
        "# Horários de Parada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34cafa58-3f20-4e80-9142-6cd6258abe4a",
      "metadata": {
        "id": "34cafa58-3f20-4e80-9142-6cd6258abe4a"
      },
      "outputs": [],
      "source": [
        "def _route_surroundings(routes, search_range):\n",
        "    # Future sjoin looses route geometry info,\n",
        "    # which will be needed, thus the backup\n",
        "    return routes.assign(\n",
        "        geometry_backup=lambda x: x.geometry,\n",
        "        geometry=lambda x: x.buffer(search_range),\n",
        "        )\n",
        "\n",
        "\n",
        "def _assign_stops_to_routes(routes, stops, search_range, epsg):\n",
        "    return (\n",
        "        stops\n",
        "        .to_crs(epsg)\n",
        "        .reindex(\n",
        "            columns=[\n",
        "                'stop_id',\n",
        "                'geometry'\n",
        "                ]\n",
        "            )\n",
        "        .sjoin(\n",
        "            _route_surroundings(\n",
        "                routes.to_crs(epsg),\n",
        "                search_range,\n",
        "                )\n",
        "            )\n",
        "        .drop(columns='index_right')\n",
        "        )\n",
        "\n",
        "\n",
        "def _distance_along_route(df):\n",
        "    stops = df.geometry\n",
        "    routes = df.geometry_backup\n",
        "    dist_traveled = [\n",
        "        int(round(r.project(s))) for r, s in zip(routes, stops)\n",
        "        ]\n",
        "\n",
        "    return dist_traveled\n",
        "\n",
        "\n",
        "def _sequentiate_stops(df):\n",
        "    return (\n",
        "        df\n",
        "        .groupby('trip_id')\n",
        "        .cumcount()\n",
        "        .add(1)\n",
        "        )\n",
        "\n",
        "\n",
        "def _set_first_distance_to_zero(df):\n",
        "    return (\n",
        "        df\n",
        "        .groupby('trip_id')\n",
        "        .shape_dist_traveled\n",
        "        .transform(\n",
        "            lambda t: [0] + t[1:].tolist()\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "def _stops_along_route(df):\n",
        "    return (\n",
        "        df\n",
        "        .assign(\n",
        "            shape_dist_traveled=_distance_along_route,\n",
        "            )\n",
        "        .sort_values(['trip_id', 'shape_dist_traveled'])\n",
        "        .assign(\n",
        "            shape_dist_traveled=_set_first_distance_to_zero,\n",
        "            )\n",
        "        .assign(\n",
        "            stop_sequence=_sequentiate_stops,\n",
        "            )\n",
        "        .sort_values(['trip_id', 'stop_sequence'])\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4e0763-9821-4404-a538-9c97ae4d2d25",
      "metadata": {
        "id": "1b4e0763-9821-4404-a538-9c97ae4d2d25"
      },
      "outputs": [],
      "source": [
        "def _pct_dist_traveled(df):\n",
        "    return (\n",
        "        df\n",
        "        .groupby('trip_id')\n",
        "        .shape_dist_traveled\n",
        "        .transform(\n",
        "            lambda t: t / t.max()\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "def _arrival_times(df):\n",
        "    stop_times = (\n",
        "        df\n",
        "        .travel_time\n",
        "        .astype(int)\n",
        "        .mul(60)\n",
        "        .mul(\n",
        "            _pct_dist_traveled(df)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    stop_times = np.where(\n",
        "        df.end_time.isnull() | df.headway_secs.isnull(),\n",
        "        stop_times + df.start_time.map(gtfs_time_to_seconds),\n",
        "        stop_times\n",
        "        )\n",
        "\n",
        "    return [seconds_to_gtfs_time(t) for t in stop_times]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b9158b4-0ed1-4249-97e7-e56a919ad937",
      "metadata": {
        "id": "7b9158b4-0ed1-4249-97e7-e56a919ad937"
      },
      "outputs": [],
      "source": [
        "def seconds_to_gtfs_time(total_seconds):\n",
        "    if np.isnan(total_seconds):\n",
        "        return total_seconds  # TODO: What to do here?\n",
        "    minutes, seconds = divmod(total_seconds, 60)\n",
        "    hours, minutes = divmod(minutes, 60)\n",
        "    time = list(map(lambda x: str(x).rjust(2, '0'), [int(hours), int(minutes), int(seconds)]))\n",
        "    return f'{time[0]}:{time[1]}:{time[2]}'\n",
        "\n",
        "\n",
        "def gtfs_time_to_seconds(gtfs_time):\n",
        "    h, m, s = gtfs_time.split(':')\n",
        "    return int(h) * 3_600 + int(m) * 60 + int(s)\n",
        "\n",
        "\n",
        "def _get_stop_times(df):\n",
        "    return (\n",
        "        df\n",
        "        .assign(\n",
        "            arrival_time=_arrival_times,\n",
        "            departure_time=lambda x: x.arrival_time,\n",
        "            )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eeaea45-09f7-472c-a6d2-cfca61f0d7a1",
      "metadata": {
        "id": "2eeaea45-09f7-472c-a6d2-cfca61f0d7a1"
      },
      "outputs": [],
      "source": [
        "def build_stop_times(\n",
        "    routes,\n",
        "    stops,\n",
        "    feed,\n",
        "    schedule,\n",
        "    search_range=10,\n",
        "    epsg=EPSG,\n",
        "    ):\n",
        "    stops = gpd.GeoDataFrame(\n",
        "        stops,\n",
        "          crs=4326,\n",
        "          geometry=gpd.points_from_xy(\n",
        "              stops.stop_lon,\n",
        "              stops.stop_lat,\n",
        "              )\n",
        "          )\n",
        "\n",
        "    stop_times = (\n",
        "        _assign_stops_to_routes(routes, stops, search_range, epsg)\n",
        "        .pipe(\n",
        "            lambda gdf: pd.merge(\n",
        "                gdf,\n",
        "                feed.trips,\n",
        "                )\n",
        "            )\n",
        "        .sort_values('shape_id')\n",
        "        .reindex(\n",
        "            columns=[\n",
        "                'trip_id',\n",
        "                'stop_id',\n",
        "                'route_id',\n",
        "                'direction_id',\n",
        "                'shape_id',\n",
        "                'geometry_backup',\n",
        "                'geometry',\n",
        "                ]\n",
        "            )\n",
        "        .pipe(_stops_along_route)\n",
        "        .merge(\n",
        "            schedule.reindex(\n",
        "                columns=[\n",
        "                    'trip_id',\n",
        "                    'start_time',\n",
        "                    'end_time',\n",
        "                    'headway_secs',\n",
        "                    'travel_time',\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "        .pipe(_get_stop_times)\n",
        "        .assign(timepoint=0)\n",
        "        .reindex(\n",
        "            columns=[\n",
        "                'trip_id',\n",
        "                'stop_sequence',\n",
        "                'stop_id',\n",
        "                'arrival_time',\n",
        "                'departure_time',\n",
        "                'shape_dist_traveled',\n",
        "                'timepoint',\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    feed.set(\n",
        "        'stop_times.txt',\n",
        "        stop_times\n",
        "        )\n",
        "\n",
        "    return feed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cc1bb95-5c2a-4e09-ba52-55cb0e49396c",
      "metadata": {
        "id": "0cc1bb95-5c2a-4e09-ba52-55cb0e49396c"
      },
      "outputs": [],
      "source": [
        "feed = build_stop_times(\n",
        "    routes,\n",
        "    feed.stops,\n",
        "    feed,\n",
        "    schedule,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e6fda6d-7ab6-4655-9873-fe15644d7dca",
      "metadata": {
        "id": "6e6fda6d-7ab6-4655-9873-fe15644d7dca"
      },
      "source": [
        "# Shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9d1f5b-09ac-4893-b8ad-9d7ef8ac815c",
      "metadata": {
        "id": "aa9d1f5b-09ac-4893-b8ad-9d7ef8ac815c"
      },
      "source": [
        "Enfim, os traçados existentes são convertidos para o formato compatível com GTFS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf130a0-937b-43f2-bfcf-9a067501f011",
      "metadata": {
        "id": "4cf130a0-937b-43f2-bfcf-9a067501f011"
      },
      "outputs": [],
      "source": [
        "def build_shape_txt(routes, feed):\n",
        "    shapes = (\n",
        "        routes\n",
        "        .to_crs(4326)\n",
        "        .assign(\n",
        "            route_points=lambda x: x.geometry.map(\n",
        "                lambda g: [Point(p) for p in g.coords]\n",
        "            ),\n",
        "        )\n",
        "        .explode(column='route_points', ignore_index=False)\n",
        "        .reset_index()\n",
        "        .set_geometry('route_points')\n",
        "        .assign(\n",
        "            shape_pt_lat=lambda x: x.geometry.y,\n",
        "            shape_pt_lon=lambda x: x.geometry.x,\n",
        "            shape_pt_sequence=lambda x: x.groupby('index').cumcount(),\n",
        "        )\n",
        "        .drop(columns=['geometry', 'route_points'])\n",
        "    )\n",
        "\n",
        "    feed.set(\n",
        "        'shapes.txt',\n",
        "        shapes\n",
        "        )\n",
        "\n",
        "    return feed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea45c5c6-6614-4a3c-9c13-32f137695f1f",
      "metadata": {
        "id": "ea45c5c6-6614-4a3c-9c13-32f137695f1f"
      },
      "outputs": [],
      "source": [
        "feed = build_shape_txt(routes, feed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feed.stop_times"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "yfaN9X6zFwsB",
        "outputId": "e76507b8-898c-416c-a799-5318f3c74fc5"
      },
      "id": "yfaN9X6zFwsB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [trip_id, stop_sequence, stop_id, arrival_time, departure_time, shape_dist_traveled, timepoint]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e2a5371-c726-456a-878d-df6a41d76220\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trip_id</th>\n",
              "      <th>stop_sequence</th>\n",
              "      <th>stop_id</th>\n",
              "      <th>arrival_time</th>\n",
              "      <th>departure_time</th>\n",
              "      <th>shape_dist_traveled</th>\n",
              "      <th>timepoint</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e2a5371-c726-456a-878d-df6a41d76220')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e2a5371-c726-456a-878d-df6a41d76220 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e2a5371-c726-456a-878d-df6a41d76220');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 562
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "758b95f7-aa77-4bf1-9c19-90701b6fd73c",
      "metadata": {
        "id": "758b95f7-aa77-4bf1-9c19-90701b6fd73c"
      },
      "source": [
        "# Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "245bae72-47d3-49b9-aed6-bbaa24fa1025",
      "metadata": {
        "id": "245bae72-47d3-49b9-aed6-bbaa24fa1025"
      },
      "outputs": [],
      "source": [
        "ptg.writers.write_feed_dangerously(\n",
        "    feed,\n",
        "    outpath=f'gtfs.zip'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}