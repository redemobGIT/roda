{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb30921c-ba31-41b3-95da-6d0611e02e29",
   "metadata": {
    "id": "fNzT3x1I-tTG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sintaxe Espacial: Métricas Configuracionais do Espaço Urbano\n",
    "\n",
    "**AUTORIA:** [REDE MOB](https://www.redemob.com.br/), com base em [aplicação para QGIS](https://github.com/gkdalcin/GAUS) desenvolvida pelo [Grupo de Pesquisa Sistemas Urbanos](https://www.ufrgs.br/sistemas-urbanos/).\n",
    "\n",
    "Este script foi desenvolvido para calcular um conjunto de métricas derivadas da Sintaxe Espacial, uma metodologia amplamente utilizada para analisar a forma como o espaço urbano é organizado e como essa organização influencia o movimento das pessoas. A Sintaxe Espacial parte da ideia de que o modo como ruas, avenidas e caminhos estão conectados entre si afeta diretamente a acessibilidade e o fluxo dentro da cidade.\n",
    "\n",
    "As métricas produzidas por este script — como conectividade, integração, escolha, profundidade e outras — ajudam a revelar quais áreas da cidade são mais centrais, acessíveis ou isoladas dentro da rede viária. Essas análises são fundamentais para o planejamento urbano e de transportes, pois permitem identificar padrões espaciais que influenciam a mobilidade, a vitalidade urbana e até mesmo a segurança.\n",
    "\n",
    "As métricas específicas que são calculadas estão detalhadas [no repositório do código original](https://github.com/gkdalcin/GAUS). Elas são calculadas a partir da rede viária do município, extraída do OpenStreetMap a partir do município definido pelo usuário. Opcionalmente, o usuário pode fornecer dados que dizem respeito aos pesos de cada nó, para as métricas que assim permitem, como a centralidade de Freeman-Krafta, por exemplo.\n",
    "\n",
    "**PANORAMA:**\n",
    "- Obtém rede viária do OpenStreetMap\n",
    "- Opcionalmente, consolida a rede viária:\n",
    "\n",
    "        Em mapas urbanos digitais, é comum que uma única interseção real — como um cruzamento ou uma rotatória — seja representada por vários pontos muito próximos entre si. Isso ocorre porque cada trecho de rua que se conecta em um local recebe um ponto (ou nó) próprio. Em cruzamentos com avenidas de pistas separadas, por exemplo, cada sentido da via é desenhado como uma linha diferente, e quando essas linhas se cruzam com outras, o modelo acaba criando até quatro pontos distintos para representar o que, na realidade, é apenas um cruzamento.\n",
    "\n",
    "        O mesmo acontece em rotatórias, onde cada rua entra e sai em pontos separados ao redor do círculo. Embora todos esses pontos façam parte de uma única interseção, o sistema os trata como múltiplas interseções por estarem ligados a diferentes trechos de rua.\n",
    "\n",
    "        Para representar isso de forma mais fiel, pode-se considerar que todos os pontos que estiverem a uma distância de até, por exemplo, 15 metros uns dos outros, pertencem à mesma interseção. Esse limite de distância pode ser ajustado de acordo com os padrões de projeto viário da região analisada. Também é importante que essa análise seja feita em uma base de dados com coordenadas projetadas, que permitam trabalhar com unidades reais de medida, como metros.\n",
    "\n",
    "        Essa concolidação, aqui, ainda opta por excluir os chamados becos sem saída, pois não representam interseções relevantes para fins de análise de conectividade urbana.\n",
    "\n",
    "- Gera [Polígonos de Thiessen](https://support.esri.com/pt-br/gis-dictionary/thiessen-polygon) ao redor de cada um dos nós da rede\n",
    "- Sobrepões esses polígonos com tabelas geográficas contendo atributos do espaço urbano (população, quantidade de empresas, áreas construída etc.) para imputar esses atributos aos nós com o uso de [interpolações espaciais por áreas](https://www.researchgate.net/profile/Nina_Lam/publication/239654534_Areal_Interpolation_A_Variant_of_the_Traditional_Spatial_Problem/links/02e7e52f13aa846a64000000/Areal-Interpolation-A-Variant-of-the-Traditional-Spatial-Problem.pdf) ou de [junções espaciais](https://geopandas.org/en/stable/gallery/spatial_joins.html).\n",
    "- Análises globais e locais, a depender dos [raios de análise](https://github.com/gkdalcin/GAUS/wiki/How-the-Analysis-Radius-Works) definidos.\n",
    "- Análises levam em conta impedâncias referentes às velocidades máximas de cada aresta, conforme obtidas via OpenStreetMap: caminhos tendem a passar por locais de maior velocidade pois lá há menos impedância.\n",
    "    - [Impedância](https://github.com/gkdalcin/GAUS/wiki/Definition-of-Distances) é o valor que representa o “custo” de atravessar um trecho da rede, normalmente relacionado ao tempo de viagem ou à velocidade — quanto maior a impedância, mais demorado ou difícil é passar por ali.\n",
    "    - Está previsto melhorar o script a fim de serem utilizadas as velocidades reais em condições de trânsito mais intenso.\n",
    "\n",
    "**Importante**: Dependendo do tamanho da cidade e de sua rede viária, o tempo de processamento pode ser relativamente elevado, podendo chegar a algumas horas. Com efeito, **refatorações estão previstas para aumentar a eficiência**. Por ora, mos testes realizados durante a construção deste script, utilizando os municípios de Niterói, São Gonçalo e Itaboraí, no estado do Rio de Janeiro, o processamento variou entre cerca de **50 minutos**, para análises mais locais, e **6 horas**, para análises globais, em um computador com as seguintes especificações:\n",
    "    \n",
    "    Processador: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz 2.59 GHz\n",
    "    RAM instalada: 16,0 GB (utilizável: 15,8 GB)\n",
    "    Tipo de sistema: Sistema operacional de 64 bits, processador baseado em x64\n",
    "\n",
    "*TODO: Pedir a júnia para ajustar isso e criar ou catar textos em português*\n",
    "\n",
    "\n",
    "**MAIS INFORMAÇÕES:**\n",
    "- [Layout da Plataforma]\n",
    "- [Sumário dos Dados Disponíveis]\n",
    "- *Lorem ipsum: Conteúdo do MOB de interesse, técnico ou de divulgação*\n",
    "\n",
    "**LINKS DE INTERESSE:**\n",
    "Detalhes teóricos para os mais curiosos podem ser encontrados em uma vasta literatura técnica e acadêmica, mas, de início, pode ser interessante começar pelas [notas de aula do professor Romulo Krafta](https://www.researchgate.net/profile/Romulo-Krafta/publication/265597665_NOTAS_DE_AULA_DE_MORFOLOGIA_URBANA/links/58cfdeb7458515b6ed8c457f/NOTAS-DE-AULA-DE-MORFOLOGIA-URBANA.pdf), as quais foram transformadas em livro.\n",
    "\n",
    "- links para materiais técnicos e acadêmicos gerais, externos, de referência a respeito do conteúdo abordado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366fa89-eab4-4e1c-9e33-2efe37736d4f",
   "metadata": {},
   "source": [
    "# Instruções\n",
    "\n",
    "Este script requer:\n",
    "1. O código do IBGE para o município\n",
    "    - Caso se deseje fazer a análise de municípios vizinhos, fornecer uma lista com os códigos do IBGE destes municípios\n",
    "  \n",
    "2. O tipo de rede a ser requisitada do OpenStreetMap:\n",
    "    - `drive`: todas as ruas públicas em que é possível dirigir, excluindo vias de serviço;\n",
    "    - `drive_service`: todas as ruas em que é possível dirigir, incluindo vias de serviço, mas exclui alguns usos como estacionamento ou acesso de emergência;\n",
    "    - `walk`: todas as ruas e caminhos que pedestres podem usar, incluindo vias de serviço — p. ex., estacionamentos — ou becos nos quais você pode andar, mesmo que sejam desconfortáveis (nesse tipo de rede, ignora-se o sentido das vias, dado que pedestres podem se mover em todas as direções);\n",
    "    - `bike`: todas as ruas e caminhos que ciclistas podem usar;\n",
    "    - `all_public`: todas as vias e caminhos públicos atualmente em uso; e\n",
    "    - `all`: todas as vias públicas ou privadas atualmente em uso.\n",
    "\n",
    "3. (opcional) Definir se a rede deve ser consolidada ou não:\n",
    "    - `consolidar_rede = False` -> Não agrega nós próximos\n",
    "    - `consolidar_rede = True` -> Agrega nós próximos\n",
    "    - Se `consolidar_rede = True` usuário deve definir `tolerancia_consolidacao`, a qual deve receber um valor em metros e, todos os nós que estão a `tolerancia_consolidacao` metros um do outros serão consolidados em um único nó. Por padrão, utiliza `tolerancia_consolidacao = 15`, mas outros valores podem ser tentados. Note que valores excessivamente altos podem distorcer a análise e valores muito baixos podem fazer com que o procedimento não agregue nó algum.\n",
    "\n",
    "4. Um dígito de 0 a 7, representando qual das [métricas de sintaxe espacial](https://github.com/gkdalcin/GAUS) se deseja calcular:\n",
    "    - 0: `Acessibilidade`, # TODO: checar tradução\n",
    "    - 1: `Intermediação`,\n",
    "    - 2: `Freeman-Krafta`,\n",
    "    - 3: `Oportunidade`,\n",
    "    - 4: `Convergência`,\n",
    "    - 5: `Polarização`,\n",
    "    - 6: `Alcance`,\n",
    "    - 7: `Conectividade`, # TODO: checar se é mesmo a equivalente a degree centrality\n",
    "5. [Raios de análise](https://github.com/gkdalcin/GAUS/wiki/How-the-Analysis-Radius-Works) em metros. Por padrão, aplica o modelo ao longo de diferentes raios (500 m, 1000 m, 2500 m, 5000 m, and global), indo, portanto, desde a escala da vizinhança até a escala de toda a área urbana.\n",
    "\n",
    "6. (Opcional) Uma tabela geográfica com os dados que serão atribuídos aos nós para ponderação, se desejado. Esses dados são então atribuídos aos nós segundo duas possibilidades:\n",
    "    - A primeira possibilidade é utilizar uma tabela geográfica com polígonos, representando, por exemplo, [dados do cadastro imobilíario do IPTU](https://bhmap.pbh.gov.br/v2/mapa/idebhgeo#zoom=5&lat=7796792.33442&lon=610634.63528&baselayer=base&layers=cadastro_imobiliario), contendo os lotes do município e a área total construída em cada um deles. Assim, cada nó recebe um peso que é tanto maior quanto maior é a área construída à sua volta. Analogamente, qualquer outro atributo armazenado em polígonos pode ser utilizado — p. ex., população em setores censitários, quantidade de atividade comercial por bairro etc.\n",
    "    - A segunda possibilidade envolve prover uma tabela geográfica com pontos, em que cada elemento da tabela tem uma coordenada geográfica associada — localização de empresas, por exemplo. Se isso for fornecido, cada nó da rede é associado ao ponto mais próximo e o peso corresponde à soma das quantidades\n",
    "    - **TODO: melhorar essa explicação: tá meio confusa**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb66dd-2f78-44d2-96e3-5d41bd5fc2dd",
   "metadata": {},
   "source": [
    "# Parâmetros Definidos Pelo Usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfeb8ac-4855-4161-ac78-3531b87af8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T01:13:01.060930Z",
     "iopub.status.busy": "2025-04-30T01:13:01.060930Z",
     "iopub.status.idle": "2025-04-30T01:13:01.069510Z",
     "shell.execute_reply": "2025-04-30T01:13:01.068964Z",
     "shell.execute_reply.started": "2025-04-30T01:13:01.060930Z"
    }
   },
   "outputs": [],
   "source": [
    "# Forneça código do IBGE da cidade, ou lista de códigos\n",
    "# se quiser cidades vizinhas. P. ex.:\n",
    "# ibge_id = 3303302 -> Niterói\n",
    "ibge_id = [3303302, 3304904, 3301900] # Niterói, São Gonçalo, Itaboraí\n",
    "\n",
    "tipo_de_rede = 'drive'\n",
    "consolidar_rede = True # Não agrega nós (interseções) muito próximos\n",
    "tolerancia_consolidacao = 15 # Apenas faz diferença se consolidar_rede = True\n",
    "\n",
    "metrica = [3, 4, 5] # Metrica de sintaxe espacial escolhida\n",
    "impedancia = 'impedance' # Por enquanto não há alternativas para isso\n",
    "raio_analise = [500, 1_000, 2_500, 5000, 0] # metros\n",
    "\n",
    "# Todo: elaborar\n",
    "tabelas_atributos = [\n",
    "    '../database/1. Socioeconômicos/rais_by_cep_2023.parquet',\n",
    "    '../database/1. Socioeconômicos/sociodemografia_2010.parquet',\n",
    "    ]\n",
    "attr_cols = [\n",
    "    ('quantidade_vinculos_ativos', 'quantidade_estabelecimentos'),\n",
    "    ('habitantes'),\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37efa6-8a5b-438b-b6e6-305365077451",
   "metadata": {},
   "source": [
    "# Backend\n",
    "\n",
    "Processamento interno do código. A princípio, o usuário não precisa se preocupar com esta parte, mas aqueles com conhecimento mais avançado de programação podem fazer ajustes de acordo com as próprias necessidades específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59a9e7-fe15-4670-b542-39776bbf394f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T01:13:13.018277Z",
     "iopub.status.busy": "2025-04-30T01:13:13.017291Z",
     "iopub.status.idle": "2025-04-30T01:13:18.085557Z",
     "shell.execute_reply": "2025-04-30T01:13:18.085557Z",
     "shell.execute_reply.started": "2025-04-30T01:13:13.018277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bibliotecas principais\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Union, Optional, List\n",
    "\n",
    "import geobr\n",
    "import geopandas as gpd\n",
    "from libpysal.cg import voronoi_frames\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from shapely.geometry import Point\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tobler.area_weighted import area_interpolate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fef46c4a-d9c9-4ea8-8dc3-f8233fcdbae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:08:48.058997Z",
     "iopub.status.busy": "2025-04-07T02:08:48.058026Z",
     "iopub.status.idle": "2025-04-07T02:08:49.387475Z",
     "shell.execute_reply": "2025-04-07T02:08:49.386456Z",
     "shell.execute_reply.started": "2025-04-07T02:08:48.058997Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_study_area(ibge_id):\n",
    "    if not isinstance(ibge_id, list):\n",
    "        ibge_id = [ibge_id]\n",
    "\n",
    "    return pd.concat([\n",
    "        geobr.read_municipality(id_)\n",
    "        for id_\n",
    "        in ibge_id\n",
    "        ]).reindex(columns=['geometry'])\n",
    "\n",
    "\n",
    "place = get_study_area(ibge_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70b6879d-e7e5-4560-a42c-eb87e534671e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:08:49.389492Z",
     "iopub.status.busy": "2025-04-07T02:08:49.389492Z",
     "iopub.status.idle": "2025-04-07T02:08:49.504069Z",
     "shell.execute_reply": "2025-04-07T02:08:49.504069Z",
     "shell.execute_reply.started": "2025-04-07T02:08:49.389492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: EPSG:31983>\n",
       "Name: SIRGAS 2000 / UTM zone 23S\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- name: Brazil - between 48°W and 42°W, northern and southern hemispheres, onshore and offshore.\n",
       "- bounds: (-48.0, -33.5, -42.0, 5.13)\n",
       "Coordinate Operation:\n",
       "- name: UTM zone 23S\n",
       "- method: Transverse Mercator\n",
       "Datum: Sistema de Referencia Geocentrico para las AmericaS 2000\n",
       "- Ellipsoid: GRS 1980\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crs = place.estimate_utm_crs(datum_name='SIRGAS 2000')\n",
    "crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3547f0b-9b50-40ad-ba9e-73e02463f273",
   "metadata": {},
   "source": [
    "Redes viárias reais são representadas por [grafos direcionados](https://pt.wikipedia.org/wiki/Grafo_orientado), [não planares](https://pt.wikipedia.org/wiki/Grafo_planar), que permitem a existência de arestas paralelas (mais de uma ligação entre os mesmos pontos) e laços (conexões de um ponto consigo mesmo). Nesse tipo de estrutura, uma rua de mão única é representada por uma única linha com direção, ligando o ponto de origem (nó `u`) ao ponto de destino (nó `v`). Já uma rua de mão dupla é representada por duas linhas sobrepostas, com sentidos opostos: uma do nó `u` para o `v`, e outra do `v` para o `u`, indicando o fluxo possível nos dois sentidos.\n",
    "\n",
    "Por serem grafos não planares, esses modelos conseguem representar corretamente situações do mundo real como viadutos, passagens subterrâneas e trevos rodoviários, onde as vias se cruzam em diferentes níveis. Assim, dois caminhos que se cruzam em um mapa bidimensional não são considerados uma interseção no modelo — a menos que exista, de fato, uma junção física entre eles no espaço tridimensional.\n",
    "\n",
    "Contudo, o algoritmo do GAUS não lida bem com casos em que há mais de um caminho possível `u` -> `v`. Nesses casos, mantém-se a via com maior hierarquia, segundo a ordem de prioridades definida abaixo. Elementos listados primeiro tem maior prioridade frente aos que vem listados depois. Ainda, o algoritmo não consegue lidar de forma alguma com laços. Esses são, então, sempre removidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "396a19d4-0045-4ca0-8809-940237fa5c8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:08:49.506074Z",
     "iopub.status.busy": "2025-04-07T02:08:49.506074Z",
     "iopub.status.idle": "2025-04-07T02:08:49.514216Z",
     "shell.execute_reply": "2025-04-07T02:08:49.513210Z",
     "shell.execute_reply.started": "2025-04-07T02:08:49.506074Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "hierarquias_viarias = [\n",
    "    # Vias principais (prioridade de navegação)\n",
    "    \"motorway\", \"motorway_link\",\n",
    "    \"trunk\", \"trunk_link\",\n",
    "    \"primary\", \"primary_link\",\n",
    "    \"secondary\", \"secondary_link\",\n",
    "    \"tertiary\", \"tertiary_link\",\n",
    "\n",
    "    # Vias locais\n",
    "    \"residential\", \"living_street\", \"service\", \"unclassified\",\n",
    "\n",
    "    # Vias que não permitem modos motorizados\n",
    "    \"path\", \"footway\", \"bridleway\", \"cycleway\", \"pedestrian\", \"steps\",\n",
    "    \n",
    "    # Estradas rurais e especiais\n",
    "    \"road\", \"track\",\n",
    "\n",
    "    # De acesso específico\n",
    "    \"corridor\", \"escape\", \"bus_guideway\", \"raceway\",\n",
    "\n",
    "    # Baixa prioidade de miscelânea\n",
    "    \"construction\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed767972-a842-4600-9268-c46b710c2528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:08:49.517218Z",
     "iopub.status.busy": "2025-04-07T02:08:49.517218Z",
     "iopub.status.idle": "2025-04-07T02:08:49.532326Z",
     "shell.execute_reply": "2025-04-07T02:08:49.532326Z",
     "shell.execute_reply.started": "2025-04-07T02:08:49.517218Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_network(\n",
    "        place,\n",
    "        hierarquias,\n",
    "        network_type='drive',\n",
    "        out_crs=31983,\n",
    "        is_simplified=True,\n",
    "        consolidate_intersections=False,\n",
    "        intersection_consolidation_tolerance=15,\n",
    "        ):\n",
    "    graph = ox.graph_from_polygon(\n",
    "        place.to_crs(4326).union_all().convex_hull,\n",
    "        network_type=network_type,\n",
    "        simplify=is_simplified,\n",
    "        )\n",
    "\n",
    "    if consolidate_intersections:\n",
    "        graph = ox.consolidate_intersections(\n",
    "            graph,\n",
    "            rebuild_graph=True,\n",
    "            tolerance=intersection_consolidation_tolerance,\n",
    "            dead_ends=True,\n",
    "            )\n",
    "\n",
    "    graph = consolidate_edges(graph, hierarquias)\n",
    "\n",
    "    return ox.project_graph(graph, to_crs=out_crs)\n",
    "\n",
    "\n",
    "def consolidate_edges(G, hierarquias):\n",
    "    invalid_bunch = _select_invalid_edges(G)\n",
    "    # GAUS does not handle self-loops\n",
    "    self_loop_bunch = list(nx.selfloop_edges(G, keys=True))\n",
    "    ebunch = self_loop_bunch.append(invalid_bunch)\n",
    "\n",
    "    if ebunch:\n",
    "        G.remove_edges_from(ebunch)\n",
    "        G.remove_nodes_from(\n",
    "            list(nx.isolates(G))\n",
    "            )\n",
    "\n",
    "    return get_largest_component(\n",
    "        _collapse_multiedges_by_highway(G, hierarquias)\n",
    "        )\n",
    "\n",
    "\n",
    "def get_largest_component(G):\n",
    "    largest_wcc = max(nx.weakly_connected_components(G), key=len)\n",
    "    \n",
    "    largest_graph = G.__class__()\n",
    "    largest_graph.add_nodes_from((n, G.nodes[n]) for n in largest_wcc)\n",
    "    if largest_graph.is_multigraph():\n",
    "        largest_graph.add_edges_from(\n",
    "            (n, nbr, key, d)\n",
    "            for n, nbrs in G.adj.items()\n",
    "            if n in largest_wcc\n",
    "            for nbr, keydict in nbrs.items()\n",
    "            if nbr in largest_wcc\n",
    "            for key, d in keydict.items()\n",
    "        )\n",
    "    else:\n",
    "        largest_graph.add_edges_from(\n",
    "            (n, nbr, d)\n",
    "            for n, nbrs in G.adj.items()\n",
    "            if n in largest_wcc\n",
    "            for nbr, d in nbrs.items()\n",
    "            if nbr in largest_wcc\n",
    "        )\n",
    "    largest_graph.graph.update(G.graph)\n",
    "\n",
    "    return largest_graph\n",
    "\n",
    "\n",
    "def _collapse_multiedges_by_highway(G, hierarquias):\n",
    "    highway_cat = CategoricalDtype(\n",
    "        categories=hierarquias, ordered=True,\n",
    "        )\n",
    "    edges = (\n",
    "        ox\n",
    "        .graph_to_gdfs(G, nodes=False)\n",
    "        .explode('highway')\n",
    "        .astype({'highway': highway_cat})\n",
    "        .sort_values(by='highway')\n",
    "        .reset_index()\n",
    "        .drop_duplicates(subset=['u', 'v'])\n",
    "        .set_index(['u', 'v', 'key'])\n",
    "        )\n",
    "    return ox.graph_from_gdfs(\n",
    "        ox.graph_to_gdfs(G, edges=False),\n",
    "        edges,\n",
    "        graph_attrs=G.graph\n",
    "        )\n",
    "\n",
    "\n",
    "def _select_invalid_edges(G):\n",
    "    \"\"\"\n",
    "    Removes edges of certain highway types that are\n",
    "    not really part of day to day paths, such as trails.\n",
    "    \"\"\"\n",
    "    h_types = [\n",
    "        'tracks',\n",
    "        'unclassified',\n",
    "        'steps',\n",
    "        'path',\n",
    "        'corridor',\n",
    "        'track',\n",
    "        ]\n",
    "    return [\n",
    "        tuple(e)\n",
    "        for *e, d\n",
    "        in G.edges(data=True, keys=True)\n",
    "        if np.isin(h_types, d.get('highway')).any() \n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c3afc72-1d56-4114-ae53-93d9e4d658a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:08:49.534369Z",
     "iopub.status.busy": "2025-04-07T02:08:49.533368Z",
     "iopub.status.idle": "2025-04-07T02:09:32.945888Z",
     "shell.execute_reply": "2025-04-07T02:09:32.943852Z",
     "shell.execute_reply.started": "2025-04-07T02:08:49.534369Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "graph = get_network(\n",
    "    place,\n",
    "    hierarquias_viarias,\n",
    "    network_type='drive',\n",
    "    out_crs=crs,\n",
    "    is_simplified=True,\n",
    "    consolidate_intersections=False,\n",
    "    intersection_consolidation_tolerance=15,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "173fab89-36ce-4318-883a-78a7cc536328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:09:32.948871Z",
     "iopub.status.busy": "2025-04-07T02:09:32.947872Z",
     "iopub.status.idle": "2025-04-07T02:09:34.814351Z",
     "shell.execute_reply": "2025-04-07T02:09:34.814351Z",
     "shell.execute_reply.started": "2025-04-07T02:09:32.948871Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "graph = ox.add_edge_speeds(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ee5d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = ox.graph_to_gdfs(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "509e8a61-cd18-4097-b4de-ab13ec84db6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:09:34.815359Z",
     "iopub.status.busy": "2025-04-07T02:09:34.815359Z",
     "iopub.status.idle": "2025-04-07T02:09:34.824473Z",
     "shell.execute_reply": "2025-04-07T02:09:34.823467Z",
     "shell.execute_reply.started": "2025-04-07T02:09:34.815359Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def impute_attributes_to_nodes(\n",
    "    nodes: gpd.GeoDataFrame,\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    study_area: gpd.GeoDataFrame,\n",
    "    attr_cols: List[str],\n",
    "    out_crs: str | int = 31983\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Impute attributes from a GeoDataFrame to nodes in an OSMnx graph.\n",
    "\n",
    "    Parameters:\n",
    "    - nodes: GDF containing nodes of a OSMnx graph\n",
    "    - gdf: GeoDataFrame with Point or Polygon geometries\n",
    "    - study_area: GeoDataFrame defining the study area\n",
    "    - attr_cols: List of attribute columns to impute (must be numeric)\n",
    "    - use_area_interpolation: Use Tobler area interpolation (for polygons only)\n",
    "    - out_crs: CRS to project geometries for spatial operations\n",
    "\n",
    "    Returns:\n",
    "    - nodes: GeoDataFrame with imputed attributes\n",
    "    \"\"\"\n",
    "    # Validate input GeoDataFrame\n",
    "    gdf, geom_types = validate_input_gdf(gdf, attr_cols)\n",
    "\n",
    "    # Create Voronoi polygons\n",
    "    node_polygons = create_voronoi_polygons(nodes, study_area, out_crs)\n",
    "\n",
    "    # Handle different geometry types using a dispatch dictionary\n",
    "    geometry_handlers = {\n",
    "        frozenset({'Polygon', 'MultiPolygon'}): handle_polygons_with_area_interpolation,\n",
    "        frozenset({'Point', 'MultiPoint'}): handle_points_with_spatial_join,\n",
    "    }\n",
    "\n",
    "    for geom_type_set, handler in geometry_handlers.items():\n",
    "        if geom_types.issubset(geom_type_set):\n",
    "            return handler(nodes, gdf, node_polygons, attr_cols, out_crs)\n",
    "\n",
    "    raise ValueError(\"Tipo de geometria não suportado no GeoDataFrame.\")\n",
    "\n",
    "\n",
    "def validate_input_gdf(\n",
    "    gdf: gpd.GeoDataFrame, attr_cols: List[str]\n",
    ") -> tuple[gpd.GeoDataFrame, set[str]]:\n",
    "    \"\"\"Validate the input GeoDataFrame and attribute columns.\"\"\"\n",
    "    if gdf.empty:\n",
    "        raise ValueError(\"O GeoDataFrame de entrada está vazio.\")\n",
    "\n",
    "    dropped_count = gdf.loc[gdf.geometry.isnull()].shape[0]\n",
    "    if dropped_count > 0:\n",
    "        print(\n",
    "            f\"Aviso: {dropped_count} geometria(s) foram descartadas por serem \"\n",
    "            \"nulas.\"\n",
    "        )\n",
    "    gdf = gdf.loc[gdf.geometry.notnull()]\n",
    "    gdf = gdf.fillna(0)\n",
    "    geom_types = set(gdf.geometry.geom_type.unique())\n",
    "\n",
    "    for col in attr_cols:\n",
    "        gdf[col] = pd.to_numeric(gdf[col], errors=\"coerce\")\n",
    "        if gdf[col].isnull().any():\n",
    "            invalid_entries = gdf.loc[gdf[col].isnull(), col]\n",
    "            if not invalid_entries.empty:\n",
    "                print(\n",
    "                    f\"Aviso: A coluna '{col}' contém entradas inválidas que \"\n",
    "                    f\"não puderam ser convertidas para valores numéricos: \"\n",
    "                    f\"{invalid_entries.tolist()}\"\n",
    "                )\n",
    "\n",
    "    return gdf, geom_types\n",
    "\n",
    "\n",
    "def create_voronoi_polygons(\n",
    "    nodes: gpd.GeoDataFrame,\n",
    "    study_area: gpd.GeoDataFrame,\n",
    "    out_crs: str | int\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Create Voronoi polygons around nodes.\"\"\"\n",
    "    return voronoi_frames(\n",
    "        nodes.to_crs(out_crs),\n",
    "        clip=study_area.to_crs(out_crs).union_all().convex_hull,\n",
    "        return_input=False,\n",
    "        as_gdf=True,\n",
    "    ).set_index(nodes.index)\n",
    "\n",
    "\n",
    "def handle_polygons_with_area_interpolation(\n",
    "    nodes: gpd.GeoDataFrame,\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    node_polygons: gpd.GeoDataFrame,\n",
    "    attr_cols: List[str],\n",
    "    out_crs: str | int,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Handle polygons using area interpolation.\"\"\"\n",
    "    interpolated = area_interpolate(\n",
    "        source_df=gdf.to_crs(out_crs),\n",
    "        target_df=node_polygons,\n",
    "        extensive_variables=attr_cols,\n",
    "        allocate_total=True,\n",
    "    )\n",
    "    for col in attr_cols:\n",
    "        nodes[col] = interpolated[col]\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def handle_points_with_spatial_join(\n",
    "    nodes: gpd.GeoDataFrame,\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    node_polygons: gpd.GeoDataFrame,\n",
    "    attr_cols: List[str],\n",
    "    out_crs: str | int,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Handle points using spatial join and dissolve.\"\"\"\n",
    "    gdf = gdf.to_crs(out_crs)\n",
    "    joined = gpd.sjoin(node_polygons, gdf, how=\"left\", predicate=\"contains\")\n",
    "    dissolved = joined.groupby(joined.index).agg(\n",
    "        {col: \"sum\" for col in attr_cols}\n",
    "    )\n",
    "    for col in attr_cols:\n",
    "        nodes[col] = dissolved[col]\n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "09fd199e-db38-446d-934f-f322e9aac724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:09:35.248994Z",
     "iopub.status.busy": "2025-04-07T02:09:35.247975Z",
     "iopub.status.idle": "2025-04-07T02:09:41.196286Z",
     "shell.execute_reply": "2025-04-07T02:09:41.195390Z",
     "shell.execute_reply.started": "2025-04-07T02:09:35.248994Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "      <th>quantidade_vinculos_ativos</th>\n",
       "      <th>quantidade_estabelecimentos</th>\n",
       "      <th>habitantes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osmid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7886733332</th>\n",
       "      <td>719764.089903</td>\n",
       "      <td>7.483499e+06</td>\n",
       "      <td>POINT (719764.09 7483499.005)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.196187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885932830</th>\n",
       "      <td>719683.092133</td>\n",
       "      <td>7.483642e+06</td>\n",
       "      <td>POINT (719683.092 7483641.899)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885807095</th>\n",
       "      <td>719757.924424</td>\n",
       "      <td>7.483495e+06</td>\n",
       "      <td>POINT (719757.924 7483495.406)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.890746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601254934</th>\n",
       "      <td>699818.946669</td>\n",
       "      <td>7.476573e+06</td>\n",
       "      <td>POINT (699818.947 7476572.743)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.611480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456678304</th>\n",
       "      <td>699813.856345</td>\n",
       "      <td>7.476541e+06</td>\n",
       "      <td>POINT (699813.856 7476541.01)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.171671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        x             y                        geometry  \\\n",
       "osmid                                                                     \n",
       "7886733332  719764.089903  7.483499e+06   POINT (719764.09 7483499.005)   \n",
       "7885932830  719683.092133  7.483642e+06  POINT (719683.092 7483641.899)   \n",
       "7885807095  719757.924424  7.483495e+06  POINT (719757.924 7483495.406)   \n",
       "2601254934  699818.946669  7.476573e+06  POINT (699818.947 7476572.743)   \n",
       "456678304   699813.856345  7.476541e+06   POINT (699813.856 7476541.01)   \n",
       "\n",
       "            quantidade_vinculos_ativos  quantidade_estabelecimentos  \\\n",
       "osmid                                                                 \n",
       "7886733332                         0.0                          0.0   \n",
       "7885932830                         0.0                          0.0   \n",
       "7885807095                         0.0                          0.0   \n",
       "2601254934                         0.0                          0.0   \n",
       "456678304                          0.0                          0.0   \n",
       "\n",
       "            habitantes  \n",
       "osmid                   \n",
       "7886733332   28.196187  \n",
       "7885932830   18.661500  \n",
       "7885807095   26.890746  \n",
       "2601254934   33.611480  \n",
       "456678304    58.171671  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputation process\n",
    "results = []\n",
    "for tabela_path, cols in zip(tabelas_atributos, attr_cols):\n",
    "    tabela = gpd.read_parquet(tabela_path)\n",
    "    result = impute_attributes_to_nodes(\n",
    "        nodes=nodes,\n",
    "        gdf=tabela,\n",
    "        study_area=place,\n",
    "        attr_cols=list(cols) if isinstance(cols, (tuple, list)) else [cols],\n",
    "        out_crs=crs\n",
    "    )\n",
    "    results.append(\n",
    "        result[list(cols) if isinstance(cols, (tuple, list)) else [cols]]\n",
    "    )\n",
    "\n",
    "# Concatenate all results along the column axis\n",
    "nodes = pd.concat(\n",
    "    [nodes[['x', 'y', 'geometry']]] + results,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "nodes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc9f8e-6ad8-4366-aff7-bb66c2521799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:09:41.247397Z",
     "iopub.status.busy": "2025-04-07T02:09:41.246397Z",
     "iopub.status.idle": "2025-04-07T02:09:41.304159Z",
     "shell.execute_reply": "2025-04-07T02:09:41.304159Z",
     "shell.execute_reply.started": "2025-04-07T02:09:41.247397Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def computeMetrics(\n",
    "        nodes,\n",
    "        edges,\n",
    "        metricsL, # list: [0 to 7], depending on metric: see NodeObj class\n",
    "        dirGraph=False, # True if dealing with a directed graph. Def: False\n",
    "        impField=None, # if not none, list (cols in edges)\n",
    "        loadField=None, # if not none, list (cols in nodes)\n",
    "        supplyField=None, # if not none, list (cols in nodes)\n",
    "        demandField=None, # if not none, list (cols in nodes)\n",
    "        analysisType=1, # 0 if merely topological\n",
    "        radius=0, # Means global network analysis\n",
    "        prec=1e-6, # max_distance to look for in sindex\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Computes configurational metrics for a network composed of points whose connections are indicated by lines.\n",
    "    \n",
    "    Fields Description:\n",
    "    Points: vector layer of the network's nodes.\n",
    "    Lines: vector layer of the network's lines.\n",
    "    Analysis: in topological analysis, the distance between connected nodes is equal to 1. In geodetic analysis, the geodetic distance between them is considered.\n",
    "    Metrics to be calculated: the selected metrics will be the ones whose result will be displayed in the attributes table.\n",
    "    Analysis Radius: only the pairs of nodes whose distance is within the defined radius will be considered for the analysis. Zero means that all pairs of nodes are considered.\n",
    "    Impedance: field of the lines vector layer containing the impedance of each line.\n",
    "    Load: field of the points vector layer containing the load of each node.\n",
    "    Supply: field of the points vector layer containing the supply of each node.\n",
    "    Demand: field of the points vector layer containing the demand of each node.\n",
    "    Distance Precision: maximum distance between point and line vertex that will be considered as a connection between them.\n",
    "    Create New Shapefile for Results?: if it is left blank, the results will be inserted in the existing nodes vector layer. Otherwise, a copy of the vector layer will be created containing the results.\n",
    "    \"\"\"\n",
    "\n",
    "    #Nodes of the network\n",
    "    class NodeObj:\n",
    "        def __init__(self, featCount, feat, loadF, supplyF, demandF, metricsL):\n",
    "            self.id = feat.Index\n",
    "            self.heapPos = -1 #current position of the node inside the heap\n",
    "            self.neighA = []  #list of connected nodes\n",
    "            \n",
    "            #configurational metrics\n",
    "            if 0 in metricsL: self.access = 0\n",
    "            if 1 in metricsL: self.btw = 0\n",
    "            if 2 in metricsL: self.cent = 0\n",
    "            if 3 in metricsL: self.opport = 0\n",
    "            if 4 in metricsL: self.converg = 0\n",
    "            if 5 in metricsL: self.polarity = 0\n",
    "            if 6 in metricsL: self.reach = 0\n",
    "            if 7 in metricsL: self.conn = 0\n",
    "            \n",
    "            #calculation weightings\n",
    "            self.load, self.supply, self.demand = 0, 0, 0\n",
    "            if loadF is None: self.load = 1\n",
    "            else:\n",
    "                for i in range(len(loadF)):\n",
    "                    load = getattr(feat, loadF[i])\n",
    "                    if not np.isnan(load): self.load += load\n",
    "            if supplyF is None: self.supply = 1\n",
    "            else:\n",
    "                for i in range(len(supplyF)):\n",
    "                    supply = getattr(feat, supplyF[i])\n",
    "                    if not np.isnan(supply): self.supply += supply\n",
    "            if demandF is None: self.demand = 1\n",
    "            else:\n",
    "                for i in range(len(demandF)):\n",
    "                    demand = getattr(feat, demandF[i])\n",
    "                    if not np.isnan(demand): self.demand += demand\n",
    "    \n",
    "    #verifies if highest id number is lower than number of features\n",
    "    #in order to avoid potential conflicts with matrices' size\n",
    "    def verifyFeatCount(inputFeat):\n",
    "        featCount = inputFeat.featureCount()\n",
    "        for feat in inputFeat.getFeatures(): featCount = max(featCount, feat.id()+1)\n",
    "        return featCount\n",
    "    \n",
    "    def defineDistance(edge, analysisType, impField):\n",
    "        if impField is None: impedance = 1\n",
    "        else:\n",
    "            impedance = 0\n",
    "            for i in range(len(impField)): \n",
    "                imp = getattr(edge, impField[i])\n",
    "                if not np.isnan(imp): impedance += imp\n",
    "            \n",
    "        dist = impedance if analysisType == 0 else impedance*edge.length\n",
    "        return dist\n",
    "        \n",
    "    \n",
    "    #nodes initialization\n",
    "    idx_name = nodes.index.name\n",
    "    inputNodes = nodes.reset_index()\n",
    "    nodesCount = len(inputNodes)\n",
    "    nodesA = [0 for i in range(nodesCount)] #array that stores network nodes\n",
    "    for node in inputNodes.itertuples(): \n",
    "        nodesA[node.Index] = NodeObj(nodesCount, node, loadField, supplyField, demandField, metricsL)\n",
    "    \n",
    "    #Initialize Edges\n",
    "    nodesSpaceIndex = inputNodes.sindex\n",
    "    inputEdges = edges\n",
    "    for edge in inputEdges.itertuples():\n",
    "        # TO DO: think of different name than eddgeVertices\n",
    "        edgesVertices = edge.geometry\n",
    "        # TO DO: check if both lines below are necessary\n",
    "        vert1 = nodesSpaceIndex.nearest(\n",
    "            Point(edgesVertices.coords[0]),\n",
    "            return_all=False,\n",
    "            max_distance=prec,\n",
    "            )[-1][0]\n",
    "        vert2 = nodesSpaceIndex.nearest(\n",
    "            Point(edgesVertices.coords[-1]),\n",
    "            return_all=False,\n",
    "            max_distance=prec,\n",
    "            )[-1][0]\n",
    "        if vert1.size > 0 and vert2.size > 0:\n",
    "            dist = defineDistance(edge, analysisType, impField)\n",
    "            if dist <= radius or radius == 0.0:\n",
    "                nodesA[vert1].neighA.append([nodesA[vert2], dist])\n",
    "                if not dirGraph: nodesA[vert2].neighA.append([nodesA[vert1], dist])\n",
    "    \n",
    "    #Compute Shortest Paths (Djikstra Algorithm with Binary Heap as Priority Queue)\n",
    "    #1-Heap cretation\n",
    "    if metricsL != [7]:\n",
    "        for source in tqdm(nodesA):\n",
    "            finitePos = 0\n",
    "            costA = [int(1e14) for i in range(nodesCount)]\n",
    "            costA[source.id] = 0 #distance from the source edge to itself is zero\n",
    "            for ind in range(len(source.neighA)): costA[source.neighA[ind][0].id] = source.neighA[ind][1]\n",
    "            heap = [nodesA[0] for i in range(len(source.neighA) + 1)]\n",
    "            for destin in nodesA:\n",
    "                if costA[destin.id] == int(1e14):\n",
    "                    heap.append(destin)\n",
    "                    destin.heapPos = len(heap) - 1\n",
    "                else:\n",
    "                    heap[finitePos] = destin\n",
    "                    destin.heapPos = finitePos\n",
    "                    n = finitePos\n",
    "                    finitePos += 1\n",
    "                    parent = int((n-1)/2)\n",
    "                    while n !=0 and costA[heap[n].id] < costA[heap[parent].id]:\n",
    "                        heap[n].heapPos, heap[parent].heapPos = parent, n\n",
    "                        heap[n], heap[parent] = heap[parent], heap[n]\n",
    "                        n = parent\n",
    "                        parent = int((n-1)/2)\n",
    "    #2-Heap sorting\n",
    "            pivotA = [[] for i in range(nodesCount)]\n",
    "            level = [0 for i in range(nodesCount)]\n",
    "            numSP = [0 for i in range(nodesCount)]\n",
    "            sortedA = [] \n",
    "            numSP[source.id], level[source.id] = 1,0\n",
    "            for ind in range(len(source.neighA)): \n",
    "                numSP[source.neighA[ind][0].id] = 1 \n",
    "                level[source.neighA[ind][0].id] = 1\n",
    "            while heap != []:\n",
    "                closest = heap[0]\n",
    "                if costA[closest.id] <= radius or radius == 0.0: sortedA.append(closest)\n",
    "                if finitePos > 0:\n",
    "                    heap[0].heapPos, heap[finitePos-1].heapPos = finitePos-1, 0\n",
    "                    heap[0], heap[finitePos-1] = heap[finitePos-1], heap[0]\n",
    "                    heap[finitePos-1].heapPos, heap[-1].heapPos = len(heap)-1, finitePos-1\n",
    "                    heap[finitePos-1], heap[-1] = heap[-1], heap[finitePos-1]\n",
    "                    finitePos -= 1\n",
    "                heap.pop(len(heap)-1)\n",
    "            \n",
    "                n = 0\n",
    "                lh = finitePos\n",
    "                posChild1, posChild2 = n*2+1, n*2+2\n",
    "                if posChild2 <= lh-1:\n",
    "                    costChild1, costChild2 = costA[heap[n*2+1].id], costA[heap[n*2+2].id]\n",
    "                    if any(x < costA[heap[n].id] for x in [costChild1,costChild2]):\n",
    "                        if costChild1 <= costChild2: sc = posChild1\n",
    "                        else: sc = posChild2\n",
    "                    else: sc = -1\n",
    "                elif posChild2 == lh:\n",
    "                    if costA[heap[n*2+1].id] < costA[heap[n].id]: sc = posChild1\n",
    "                    else: sc = -1\n",
    "                else: sc = -1\n",
    "                \n",
    "                while sc >= 0:\n",
    "                    heap[n].heapPos, heap[sc].heapPos = sc, n\n",
    "                    heap[n], heap[sc] = heap[sc], heap[n]\n",
    "                    n = sc\n",
    "                    lh = len(heap)\n",
    "                    posChild1, posChild2 = n*2+1, n*2+2\n",
    "                    if posChild2 <= lh-1:\n",
    "                        costChild1, costChild2 = costA[heap[n*2+1].id], costA[heap[n*2+2].id]\n",
    "                        if any(x < costA[heap[n].id] for x in [costChild1,costChild2]):\n",
    "                            if costChild1 <= costChild2: sc = posChild1\n",
    "                            else: sc = posChild2\n",
    "                        else: sc = -1\n",
    "                    elif posChild2 == lh:\n",
    "                        if costA[heap[n*2+1].id] < costA[heap[n].id]: sc = posChild1\n",
    "                        else: sc = -1\n",
    "                    else: sc = -1\n",
    "            \n",
    "                for ind in range(len(closest.neighA)):\n",
    "                    if closest.neighA[ind][0].heapPos < len(heap):\n",
    "                        cost = costA[closest.id] + closest.neighA[ind][1]\n",
    "                        prevCost = costA[closest.neighA[ind][0].id]\n",
    "                        if prevCost > cost and (radius == 0.0 or cost <= radius):\n",
    "                            costA[closest.neighA[ind][0].id], level[closest.neighA[ind][0].id] = cost, level[closest.id] + 1\n",
    "                            pivotA[closest.neighA[ind][0].id] = []\n",
    "                            pivotA[closest.neighA[ind][0].id].append(closest)\n",
    "                            numSP[closest.neighA[ind][0].id] += numSP[closest.id]\n",
    "                        \n",
    "                            n = closest.neighA[ind][0].heapPos\n",
    "                            if prevCost == int(1e14): \n",
    "                                heap[finitePos].heapPos, closest.neighA[ind][0].heapPos = n, finitePos\n",
    "                                heap[n], heap[finitePos] = heap[finitePos], closest.neighA[ind][0]\n",
    "                                n = finitePos\n",
    "                                finitePos += 1\n",
    "                            parent = int((n-1)/2)\n",
    "                            while n !=0 and costA[heap[n].id] < costA[heap[parent].id]:\n",
    "                                heap[n].heapPos, heap[parent].heapPos = parent, n\n",
    "                                heap[n], heap[parent] = heap[parent], heap[n]\n",
    "                                n = parent\n",
    "                                parent = int((n-1)/2)\n",
    "\n",
    "                        elif source.id != closest.id and costA[closest.neighA[ind][0].id] == cost and (radius == 0.0 or cost <= radius):\n",
    "                            pivotA[closest.neighA[ind][0].id].append(closest)\n",
    "                            numSP[closest.neighA[ind][0].id] += numSP[closest.id]\n",
    "                \n",
    "            #3-Metrics update\n",
    "            if 1 in metricsL: btwTemp = [0 for i in range(nodesCount)] \n",
    "            if 2 in metricsL: fkcTemp = [0 for i in range(nodesCount)]\n",
    "            if 4 in metricsL or 5 in metricsL: cvgTemp = [0 for i in range(nodesCount)]\n",
    "            while sortedA != []:\n",
    "                farest = sortedA[-1]\n",
    "                cost = costA[farest.id]\n",
    "                if radius == 0.0 or cost <= radius: \n",
    "                    if 0 in metricsL and farest.id != source.id: source.access += farest.load/costA[farest.id]\n",
    "                    if 3 in metricsL and source.demand > 0: source.opport += farest.supply/(costA[farest.id]+1)\n",
    "                    if 6 in metricsL: source.reach += farest.load\n",
    "                sortedA.pop(len(sortedA)-1)\n",
    "                pot = farest.load * source.load\n",
    "                tension = source.supply*farest.demand \n",
    "                \n",
    "                for neigh in pivotA[farest.id]:\n",
    "                    if radius == 0.0 or cost <= radius:\n",
    "                        if 1 in metricsL: btwTemp[neigh.id] += (numSP[neigh.id]/numSP[farest.id])*(1 + btwTemp[farest.id])\n",
    "                        if 2 in metricsL: fkcTemp[neigh.id] += (numSP[neigh.id]/numSP[farest.id])*((pot/(level[farest.id]+1))+fkcTemp[farest.id])\n",
    "                        if 4 in metricsL or 5 in metricsL: cvgTemp[neigh.id] += (numSP[neigh.id]/numSP[farest.id])*((tension/(level[farest.id]+1))+cvgTemp[farest.id])\n",
    "                \n",
    "                if pivotA[farest.id] == [] and level[farest.id] == 1 and (radius == 0.0 or cost <= radius): \n",
    "                    if 2 in metricsL: fkcTemp[source.id] += (pot/2)+fkcTemp[farest.id]\n",
    "                    if 4 in metricsL or 5 in metricsL: cvgTemp[source.id] += (numSP[neigh.id]/numSP[farest.id])*((tension/(level[farest.id]+1))+cvgTemp[farest.id])\n",
    "                \n",
    "                if farest.id != source.id and (radius == 0.0 or cost <= radius): \n",
    "                    if 1 in metricsL: farest.btw += btwTemp[farest.id] / (1 if dirGraph else 2)\n",
    "                    if 2 in metricsL: fkcTemp[farest.id] += pot/(level[farest.id]+1)\n",
    "                if (4 in metricsL or 5 in metricsL) and (radius == 0.0 or cost <= radius): cvgTemp[farest.id] += tension/(level[farest.id]+1)\n",
    "                \n",
    "                if 2 in metricsL: farest.cent += fkcTemp[farest.id] / (1 if dirGraph else 2)\n",
    "                if 4 in metricsL and farest.supply > 0: farest.converg += cvgTemp[farest.id]\n",
    "                if 5 in metricsL: farest.polarity += cvgTemp[farest.id]\n",
    "            \n",
    "    if 7 in metricsL:\n",
    "        for node in nodesA:\n",
    "            node.conn = len(node.neighA)\n",
    "            \n",
    "    \n",
    "    #update table of contents\n",
    "    strBegin = \"Top\" if analysisType == 0 else \"Geo\"\n",
    "    strMid = \"_Glob\" if radius == 0 else '_R'+str(int(radius))\n",
    "    strBegin += strMid\n",
    "\n",
    "    acronym_by_metric_id = {\n",
    "        0: 'access',\n",
    "        1: 'btw',\n",
    "        2: 'cent',\n",
    "        3: 'opport',\n",
    "        4: 'converg',\n",
    "        5: 'polarity',\n",
    "        6: 'reach',\n",
    "        7: 'conn',\n",
    "        }\n",
    "    metricsD = defaultdict(dict)\n",
    "    for metric_id in metricsL:\n",
    "        acro = acronym_by_metric_id.get(metric_id)\n",
    "        #col_name = strBegin + '_' + acro\n",
    "        col_name = acro\n",
    "        for node in nodesA:\n",
    "            metricsD[node.id][col_name] = getattr(node, acro)\n",
    "        \n",
    "    metrics_by_node = pd.DataFrame.from_dict(metricsD, orient='index')\n",
    "\n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        metrics_by_node[metrics_by_node.columns] = scaler.fit_transform(\n",
    "            metrics_by_node[metrics_by_node.columns]\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        inputNodes\n",
    "        .merge(\n",
    "            metrics_by_node,\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='left'\n",
    "            )\n",
    "        .set_index(idx_name)\n",
    "        )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4e195730-1406-45e5-9a04-ebdad231af18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:09:41.306166Z",
     "iopub.status.busy": "2025-04-07T02:09:41.305164Z",
     "iopub.status.idle": "2025-04-07T02:11:17.746254Z",
     "shell.execute_reply": "2025-04-07T02:11:17.745249Z",
     "shell.execute_reply.started": "2025-04-07T02:09:41.306166Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics_for_radii(\n",
    "    nodes: gpd.GeoDataFrame,\n",
    "    edges: gpd.GeoDataFrame,\n",
    "    metricsL: List[int],\n",
    "    radii: List[float],\n",
    "    dirGraph: bool = False,\n",
    "    impField: Optional[List[str]] = None,\n",
    "    loadField: Optional[List[str]] = None,\n",
    "    supplyField: Optional[List[str]] = None,\n",
    "    demandField: Optional[List[str]] = None,\n",
    "    analysisType: int = 1,\n",
    "    prec: float = 1e-6,\n",
    "    save_dir: Optional[Union[str, Path]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute metrics for multiple radii and combine results.\n",
    "\n",
    "    Parameters:\n",
    "    - nodes: GeoDataFrame of network nodes.\n",
    "    - edges: GeoDataFrame of network edges.\n",
    "    - metricsL: List of metric IDs to compute (0–7).\n",
    "    - radii: List of radii (in meters) for analysis.\n",
    "    - dirGraph: Boolean indicating if the graph is directed.\n",
    "    - impField: List of impedance fields in edges (optional).\n",
    "    - loadField: List of load fields in nodes (optional).\n",
    "    - supplyField: List of supply fields in nodes (optional).\n",
    "    - demandField: List of demand fields in nodes (optional).\n",
    "    - analysisType: 0 for topological analysis, 1 for geodetic analysis.\n",
    "    - prec: Precision for spatial index lookups.\n",
    "    - save_dir: Optional path (str or pathlib.Path) to save the combined results as a Parquet file.\n",
    "\n",
    "    Returns:\n",
    "    - Combined GeoDataFrame with metrics for all radii.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for radius in radii:\n",
    "        print(f\"Computing metrics for radius: {radius} meters...\")\n",
    "        metrics_by_node = computeMetrics(\n",
    "            nodes=nodes,\n",
    "            edges=edges,\n",
    "            metricsL=metricsL,\n",
    "            dirGraph=dirGraph,\n",
    "            impField=impField,\n",
    "            loadField=loadField,\n",
    "            supplyField=supplyField,\n",
    "            demandField=demandField,\n",
    "            analysisType=analysisType,\n",
    "            radius=radius,\n",
    "            prec=prec,\n",
    "        )\n",
    "        # Add a column to indicate the radius used\n",
    "        metrics_by_node[\"radius\"] = radius\n",
    "        results.append(metrics_by_node)\n",
    "\n",
    "    # Combine results for all radii into a single DataFrame\n",
    "    combined_results = pd.concat(results, axis=0)\n",
    "\n",
    "    # Save to Parquet if a save path is provided\n",
    "    if save_dir:\n",
    "        save_path = Path(save_dir) / \"configurational_metrics.parquet\"\n",
    "        print(f\"Saving combined results to {save_path}...\")\n",
    "        combined_results.to_parquet(save_path)\n",
    "\n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3e791178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for radius: 1000 meters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30734/30734 [56:28<00:00,  9.07it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for radius: 2500 meters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30734/30734 [1:00:45<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for radius: 5000 meters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30734/30734 [1:14:49<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for radius: 10000 meters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30734/30734 [1:57:11<00:00,  4.37it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for radius: 0 meters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30734/30734 [5:52:40<00:00,  1.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving combined results to ..\\database\\3. Urbanísticos\\configurational_metrics.parquet...\n"
     ]
    }
   ],
   "source": [
    "radii = [1_000, 2_500, 5000, 10_000, 0]  # List of radii in meters\n",
    "output_dir = Path('../database/3. Urbanísticos')\n",
    "\n",
    "# Compute metrics for all radii and save to a Parquet file\n",
    "combined_metrics = compute_metrics_for_radii(\n",
    "    nodes=nodes,\n",
    "    edges=edges,\n",
    "    metricsL=metrica,\n",
    "    radii=radii,\n",
    "    dirGraph=False if tipo_de_rede == \"walk\" else True,\n",
    "    supplyField=[\"habitantes\"],\n",
    "    demandField=[\"quantidade_vinculos_ativos\"],\n",
    "    prec=1,\n",
    "    save_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d892b1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "      <th>quantidade_vinculos_ativos</th>\n",
       "      <th>quantidade_estabelecimentos</th>\n",
       "      <th>habitantes</th>\n",
       "      <th>opport</th>\n",
       "      <th>converg</th>\n",
       "      <th>polarity</th>\n",
       "      <th>radius</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osmid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7886733332</th>\n",
       "      <td>719764.089903</td>\n",
       "      <td>7.483499e+06</td>\n",
       "      <td>POINT (719764.09 7483499.005)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.196187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5463.966552</td>\n",
       "      <td>5463.966552</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885932830</th>\n",
       "      <td>719683.092133</td>\n",
       "      <td>7.483642e+06</td>\n",
       "      <td>POINT (719683.092 7483641.899)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.661500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8047.116821</td>\n",
       "      <td>8047.116821</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885807095</th>\n",
       "      <td>719757.924424</td>\n",
       "      <td>7.483495e+06</td>\n",
       "      <td>POINT (719757.924 7483495.406)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.890746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22596.438392</td>\n",
       "      <td>22596.438392</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601254934</th>\n",
       "      <td>699818.946669</td>\n",
       "      <td>7.476573e+06</td>\n",
       "      <td>POINT (699818.947 7476572.743)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.611480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283438.986377</td>\n",
       "      <td>283438.986377</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456678304</th>\n",
       "      <td>699813.856345</td>\n",
       "      <td>7.476541e+06</td>\n",
       "      <td>POINT (699813.856 7476541.01)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.171671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295585.423446</td>\n",
       "      <td>295585.423446</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        x             y                        geometry  \\\n",
       "osmid                                                                     \n",
       "7886733332  719764.089903  7.483499e+06   POINT (719764.09 7483499.005)   \n",
       "7885932830  719683.092133  7.483642e+06  POINT (719683.092 7483641.899)   \n",
       "7885807095  719757.924424  7.483495e+06  POINT (719757.924 7483495.406)   \n",
       "2601254934  699818.946669  7.476573e+06  POINT (699818.947 7476572.743)   \n",
       "456678304   699813.856345  7.476541e+06   POINT (699813.856 7476541.01)   \n",
       "\n",
       "            quantidade_vinculos_ativos  quantidade_estabelecimentos  \\\n",
       "osmid                                                                 \n",
       "7886733332                         0.0                          0.0   \n",
       "7885932830                         0.0                          0.0   \n",
       "7885807095                         0.0                          0.0   \n",
       "2601254934                         0.0                          0.0   \n",
       "456678304                          0.0                          0.0   \n",
       "\n",
       "            habitantes  opport        converg       polarity  radius  \n",
       "osmid                                                                 \n",
       "7886733332   28.196187     0.0    5463.966552    5463.966552    1000  \n",
       "7885932830   18.661500     0.0    8047.116821    8047.116821    1000  \n",
       "7885807095   26.890746     0.0   22596.438392   22596.438392    1000  \n",
       "2601254934   33.611480     0.0  283438.986377  283438.986377    1000  \n",
       "456678304    58.171671     0.0  295585.423446  295585.423446    1000  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bbd089-47c8-4aff-bbaa-9b219794d4a2",
   "metadata": {},
   "source": [
    "# Exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23376047-8d26-43aa-9525-d042101cff13",
   "metadata": {},
   "source": [
    "**Objetivo:**  \n",
    "Explorar a **estrutura topológica do espaço urbano** usando métricas da biblioteca GAUS para **avaliar padrões de acessibilidade, conectividade e centralidade espacial**, com foco em possíveis implicações para a **mobilidade urbana** e o **acesso equitativo a oportunidades**.\n",
    "\n",
    "### Perguntas Norteadoras\n",
    "Abaixo estão potenciais vias de investigação. Escolha aquela ou aquelas que soam mais interessantes para praticar o uso da biblioteca GAUS>\n",
    "\n",
    "1. **Quais áreas são morfologicamente isoladas?**\n",
    "   - Identifique regiões com **baixa `CONNECTIVITY` e baixo `REACH`**.\n",
    "   - Há bairros com muitos nós (e.g. quarteirões, ruas), mas pouca conexão real?\n",
    "   - Essas regiões coincidem com áreas periféricas ou mal atendidas por transporte público?\n",
    "\n",
    "   > **Insight esperado**: Espaços com pouca conexão tendem a ter menor acessibilidade e mais dificuldade de integração funcional à cidade.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Onde estão os corredores estruturantes da malha urbana?**\n",
    "   - Identifique os segmentos ou entidades com **alto `BETWEENNESS` e `FREEMAN-KRAFTA CENTRALITY`**.\n",
    "   - Essas áreas funcionam como **elos de ligação entre diferentes regiões**?\n",
    "   - Essas vias coincidem com infraestrutura de transporte de massa (ex: corredores BRT, metrô, trem)?\n",
    "\n",
    "   > **Insight esperado**: Essas métricas revelam os elementos **estrategicamente centrais** da cidade — importantes para priorização de investimentos.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Como está a distribuição de oportunidades urbanas?**\n",
    "   - Analise a métrica `OPPORTUNITY` para entender quais áreas (principalmente as de demanda) **têm maior acesso a pontos de interesse**.\n",
    "   - Compare com áreas de baixa `ACCESSIBILITY`: há regiões com alta densidade, mas pouco acesso a serviços essenciais?\n",
    "   - Use `CONVERGENCE` para identificar **quais pontos de oferta são de mais fácil acsso** pela estrutura morfológica existente.\n",
    "\n",
    "   > **Insight esperado**: Desigualdades estruturais no acesso a oportunidades podem indicar necessidade de intervenções em infraestrutura ou redistribuição de serviços.\n",
    "\n",
    "---\n",
    "\n",
    "4. **Polos locais e periferias funcionais**\n",
    "   - A métrica `POLARITY` pode ajudar a **identificar centros locais** (alto valor) e periferias funcionais (valores muito baixos).\n",
    "   - Relacione `POLARITY` com `REACH`: áreas com muitos vizinhos, mas baixa polaridade, têm influência limitada?\n",
    "   - Essas periferias funcionais coincidem com áreas de vulnerabilidade socioespacial?\n",
    "\n",
    "   > **Insight esperado**: A análise pode revelar regiões que são **centralmente localizadas geograficamente**, mas **marginalizadas funcionalmente**.\n",
    "\n",
    "---\n",
    "\n",
    "### Ferramentas sugeridas:\n",
    "\n",
    "- `geopandas` – para leitura e análise espacial.\n",
    "- `networkx` – para inspeção adicional das redes se necessário.\n",
    "- `matplotlib`, `seaborn` – para gráficos comparativos.\n",
    "- `folium` ou `keplergl` – para visualização espacial interativa.\n",
    "\n",
    "---\n",
    "\n",
    "### Produto Possíveis:\n",
    "\n",
    "- Mapas temáticos.\n",
    "- Gráficos de dispersão/correlação cruzando métricas.\n",
    "- Texto analítico respondendo às perguntas acima e discutindo **impactos para o transporte público**, **mobilidade ativa**, ou **desigualdade espacial**.\n",
    "\n",
    "---\n",
    "\n",
    "**Extra**: tente criar [clusters morfológicos](https://geographicdata.science/book/notebooks/10_clustering_and_regionalization.html#) com base nas métricas e verifique se eles correspondem às regiões administrativas, zonas urbanas ou planos diretores existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e2f06-3604-45ba-8579-69170df925b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
